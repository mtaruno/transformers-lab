[
  {
    "decode_length": 32,
    "log_decode_length": 5.0,
    "prefill_time": 2.8193626403808594,
    "decode_time": 0.9288299083709717,
    "total_time": 3.748192548751831,
    "prefill_op_times": {
      "input_preparation": 0.0003922240138053894,
      "kv_cache_allocation": 0.0006446080207824707,
      "flashinfer_planning": 0.03625299072265625,
      "embedding_lookup": 0.05424643325805664,
      "transformer_layers": {
        "layer_time": 2.487946775436401,
        "attention_time": 1.845990475654602,
        "ffn_time": 0.6397450942993163,
        "detailed_layers": {
          "layer_0": {
            "total": 1.8578038330078126,
            "attention": {
              "total": 1.682860107421875,
              "qkv_proj": 0.4774739990234375,
              "rope": 0.002466752052307129,
              "kv_append": 0.902434326171875,
              "attention_op": 0.2932171020507813,
              "o_proj": 0.007083231925964355
            },
            "ffn": 0.1748641662597656
          },
          "layer_1": {
            "total": 0.019684288024902345,
            "attention": {
              "total": 0.005352672100067139,
              "qkv_proj": 0.002572448015213013,
              "rope": 0.00024326400458812714,
              "kv_append": 0.0003252800107002258,
              "attention_op": 0.0006342399716377259,
              "o_proj": 0.0014093439579010009
            },
            "ffn": 0.014239775657653808
          },
          "layer_2": {
            "total": 0.019573343276977538,
            "attention": {
              "total": 0.005244927883148193,
              "qkv_proj": 0.0025783679485321047,
              "rope": 0.0002227199971675873,
              "kv_append": 0.00024991999566555026,
              "attention_op": 0.0006136320233345032,
              "o_proj": 0.0014125759601593018
            },
            "ffn": 0.014242879867553711
          },
          "layer_3": {
            "total": 0.019758527755737304,
            "attention": {
              "total": 0.005218751907348633,
              "qkv_proj": 0.002569888114929199,
              "rope": 0.00022012799978256227,
              "kv_append": 0.00023763200640678406,
              "attention_op": 0.0006147840023040771,
              "o_proj": 0.0014178880453109741
            },
            "ffn": 0.01446224021911621
          },
          "layer_4": {
            "total": 0.020426271438598632,
            "attention": {
              "total": 0.005230271816253662,
              "qkv_proj": 0.002634848117828369,
              "rope": 0.0002109760046005249,
              "kv_append": 0.00018572799861431123,
              "attention_op": 0.0006594560146331787,
              "o_proj": 0.0014245760440826415
            },
            "ffn": 0.015112319946289062
          },
          "layer_5": {
            "total": 0.020438720703125,
            "attention": {
              "total": 0.00526262378692627,
              "qkv_proj": 0.0026453120708465577,
              "rope": 0.00021411199867725372,
              "kv_append": 0.00018652799725532533,
              "attention_op": 0.000666271984577179,
              "o_proj": 0.0014322559833526611
            },
            "ffn": 0.015111136436462402
          },
          "layer_6": {
            "total": 0.02045462417602539,
            "attention": {
              "total": 0.00526470422744751,
              "qkv_proj": 0.0026445760726928713,
              "rope": 0.00021430400013923645,
              "kv_append": 0.00018835200369358063,
              "attention_op": 0.0006655359864234925,
              "o_proj": 0.001431455969810486
            },
            "ffn": 0.015123711585998536
          },
          "layer_7": {
            "total": 0.02040812873840332,
            "attention": {
              "total": 0.005285344123840332,
              "qkv_proj": 0.002643647909164429,
              "rope": 0.00021187199652194976,
              "kv_append": 0.00020851199328899384,
              "attention_op": 0.0006685760021209716,
              "o_proj": 0.0014360959529876708
            },
            "ffn": 0.01505840015411377
          },
          "layer_8": {
            "total": 0.02045801544189453,
            "attention": {
              "total": 0.005245888233184814,
              "qkv_proj": 0.0026355199813842775,
              "rope": 0.000213919997215271,
              "kv_append": 0.0001884160041809082,
              "attention_op": 0.0006625919938087464,
              "o_proj": 0.0014280320405960082
            },
            "ffn": 0.01512342357635498
          },
          "layer_9": {
            "total": 0.02049590492248535,
            "attention": {
              "total": 0.005289216041564942,
              "qkv_proj": 0.0026538240909576415,
              "rope": 0.0002168000042438507,
              "kv_append": 0.00019795200228691102,
              "attention_op": 0.0006692479848861695,
              "o_proj": 0.0014334399700164796
            },
            "ffn": 0.015140576362609863
          },
          "layer_10": {
            "total": 0.020469215393066405,
            "attention": {
              "total": 0.005275648117065429,
              "qkv_proj": 0.0026496319770812986,
              "rope": 0.00021583999693393707,
              "kv_append": 0.0001887039989233017,
              "attention_op": 0.0006683200001716614,
              "o_proj": 0.0014353920221328736
            },
            "ffn": 0.015127264022827148
          },
          "layer_11": {
            "total": 0.020425983428955078,
            "attention": {
              "total": 0.005277184009552002,
              "qkv_proj": 0.002646752119064331,
              "rope": 0.00021408000588417052,
              "kv_append": 0.0001913920044898987,
              "attention_op": 0.0006687039732933044,
              "o_proj": 0.001437119960784912
            },
            "ffn": 0.015081184387207031
          },
          "layer_12": {
            "total": 0.020247488021850585,
            "attention": {
              "total": 0.0052370882034301755,
              "qkv_proj": 0.0026370561122894287,
              "rope": 0.00021430400013923645,
              "kv_append": 0.00018848000466823578,
              "attention_op": 0.0006587200164794922,
              "o_proj": 0.0014216320514678954
            },
            "ffn": 0.014947487831115722
          },
          "layer_13": {
            "total": 0.020180543899536132,
            "attention": {
              "total": 0.005225183963775634,
              "qkv_proj": 0.0026234240531921387,
              "rope": 0.00021478399634361267,
              "kv_append": 0.0001881919950246811,
              "attention_op": 0.0006567360162734985,
              "o_proj": 0.0014213759899139404
            },
            "ffn": 0.014889887809753418
          },
          "layer_14": {
            "total": 0.020334463119506836,
            "attention": {
              "total": 0.005232223987579346,
              "qkv_proj": 0.0026275200843811036,
              "rope": 0.00021468800306320192,
              "kv_append": 0.0001871040016412735,
              "attention_op": 0.0006628479957580567,
              "o_proj": 0.0014263360500335694
            },
            "ffn": 0.015036704063415528
          },
          "layer_15": {
            "total": 0.020299711227416993,
            "attention": {
              "total": 0.00524351978302002,
              "qkv_proj": 0.002632704019546509,
              "rope": 0.00021436800062656403,
              "kv_append": 0.0001908160001039505,
              "attention_op": 0.0006660479903221131,
              "o_proj": 0.0014228479862213135
            },
            "ffn": 0.014990367889404298
          },
          "layer_16": {
            "total": 0.020439712524414063,
            "attention": {
              "total": 0.005252831935882568,
              "qkv_proj": 0.0026413118839263916,
              "rope": 0.00021267199516296386,
              "kv_append": 0.00018783999979496,
              "attention_op": 0.000665343999862671,
              "o_proj": 0.001428928017616272
            },
            "ffn": 0.01512185573577881
          },
          "layer_17": {
            "total": 0.020434303283691405,
            "attention": {
              "total": 0.005271135807037353,
              "qkv_proj": 0.0026503679752349855,
              "rope": 0.00021251200139522553,
              "kv_append": 0.00018624000251293182,
              "attention_op": 0.0006704000234603882,
              "o_proj": 0.00142684805393219
            },
            "ffn": 0.015098496437072754
          },
          "layer_18": {
            "total": 0.02057980728149414,
            "attention": {
              "total": 0.00530838394165039,
              "qkv_proj": 0.0026663680076599123,
              "rope": 0.00021801599860191346,
              "kv_append": 0.00018937599658966066,
              "attention_op": 0.0006728000044822692,
              "o_proj": 0.001445024013519287
            },
            "ffn": 0.015204671859741212
          },
          "layer_19": {
            "total": 0.020576032638549804,
            "attention": {
              "total": 0.0052977919578552244,
              "qkv_proj": 0.0026601920127868653,
              "rope": 0.00021267199516296386,
              "kv_append": 0.00018960000574588776,
              "attention_op": 0.0006728960275650024,
              "o_proj": 0.0014455360174179077
            },
            "ffn": 0.015212351799011231
          },
          "layer_20": {
            "total": 0.020584127426147462,
            "attention": {
              "total": 0.005310912132263184,
              "qkv_proj": 0.0026632959842681886,
              "rope": 0.00023231999576091766,
              "kv_append": 0.0001860799938440323,
              "attention_op": 0.0006717119812965393,
              "o_proj": 0.0014359040260314942
            },
            "ffn": 0.0152042236328125
          },
          "layer_21": {
            "total": 0.020466880798339845,
            "attention": {
              "total": 0.005294271945953369,
              "qkv_proj": 0.002662400007247925,
              "rope": 0.00021376000344753266,
              "kv_append": 0.0001894720047712326,
              "attention_op": 0.0006717759966850281,
              "o_proj": 0.0014368640184402467
            },
            "ffn": 0.015106656074523927
          },
          "layer_22": {
            "total": 0.02044300842285156,
            "attention": {
              "total": 0.0052709121704101565,
              "qkv_proj": 0.0026466879844665525,
              "rope": 0.00021420800685882567,
              "kv_append": 0.0001859840005636215,
              "attention_op": 0.0006695359945297242,
              "o_proj": 0.001433791995048523
            },
            "ffn": 0.015105312347412109
          },
          "layer_23": {
            "total": 0.02039276885986328,
            "attention": {
              "total": 0.005271903991699219,
              "qkv_proj": 0.0026489601135253906,
              "rope": 0.00021299199759960174,
              "kv_append": 0.0001924159973859787,
              "attention_op": 0.0006674879789352417,
              "o_proj": 0.0014317760467529297
            },
            "ffn": 0.015057184219360352
          },
          "layer_24": {
            "total": 0.020509567260742188,
            "attention": {
              "total": 0.005277472019195557,
              "qkv_proj": 0.0026537280082702635,
              "rope": 0.0002147199958562851,
              "kv_append": 0.00018502399325370789,
              "attention_op": 0.0006726719737052918,
              "o_proj": 0.0014336960315704346
            },
            "ffn": 0.01516755199432373
          },
          "layer_25": {
            "total": 0.020401056289672852,
            "attention": {
              "total": 0.0052531838417053224,
              "qkv_proj": 0.002642911911010742,
              "rope": 0.00021235199272632598,
              "kv_append": 0.00019033600389957428,
              "attention_op": 0.0006671680212020874,
              "o_proj": 0.0014233280420303345
            },
            "ffn": 0.015080896377563477
          },
          "layer_26": {
            "total": 0.020252256393432616,
            "attention": {
              "total": 0.005253568172454834,
              "qkv_proj": 0.002637216091156006,
              "rope": 0.0002165759950876236,
              "kv_append": 0.00019894400238990785,
              "attention_op": 0.0006674559712409973,
              "o_proj": 0.0014153599739074707
            },
            "ffn": 0.014931424140930176
          },
          "layer_27": {
            "total": 0.020130464553833008,
            "attention": {
              "total": 0.005211008071899414,
              "qkv_proj": 0.002616640090942383,
              "rope": 0.00021171200275421143,
              "kv_append": 0.0001912959963083267,
              "attention_op": 0.000657535970211029,
              "o_proj": 0.001416192054748535
            },
            "ffn": 0.014856191635131836
          },
          "layer_28": {
            "total": 0.020269887924194336,
            "attention": {
              "total": 0.00522547197341919,
              "qkv_proj": 0.002619391918182373,
              "rope": 0.00021513600647449493,
              "kv_append": 0.00018624000251293182,
              "attention_op": 0.0006576640009880066,
              "o_proj": 0.0014164799451828003
            },
            "ffn": 0.014981311798095703
          },
          "layer_29": {
            "total": 0.020486623764038085,
            "attention": {
              "total": 0.005285056114196778,
              "qkv_proj": 0.00266431999206543,
              "rope": 0.00021302400529384614,
              "kv_append": 0.00018559999763965608,
              "attention_op": 0.0006728960275650024,
              "o_proj": 0.001434559941291809
            },
            "ffn": 0.01513532829284668
          },
          "layer_30": {
            "total": 0.02028233528137207,
            "attention": {
              "total": 0.005236288070678711,
              "qkv_proj": 0.002632352113723755,
              "rope": 0.00021638399362564086,
              "kv_append": 0.00018854400515556336,
              "attention_op": 0.0006628479957580567,
              "o_proj": 0.001419935941696167
            },
            "ffn": 0.014981087684631347
          },
          "layer_31": {
            "total": 0.020238880157470704,
            "attention": {
              "total": 0.00522492790222168,
              "qkv_proj": 0.002631743907928467,
              "rope": 0.00021302400529384614,
              "kv_append": 0.00018825599551200868,
              "attention_op": 0.0006567040085792542,
              "o_proj": 0.0014158400297164917
            },
            "ffn": 0.014949024200439453
          }
        }
      },
      "lm_head": 0.16489375305175782
    },
    "last_decode_op_times": {
      "input_preparation": 0.00020268799364566803,
      "kv_cache_allocation": 0.0003227519989013672,
      "flashinfer_planning": 0.00012550400197505952,
      "embedding_lookup": 2.9184000566601752e-05,
      "transformer_layers": {
        "layer_time": 0.024491808056831363,
        "attention_time": 0.015359744042158128,
        "ffn_time": 0.007714591994881632,
        "detailed_layers": {
          "layer_0": {
            "total": 0.000807807981967926,
            "attention": {
              "total": 0.0005225600004196167,
              "qkv_proj": 0.00014575999975204468,
              "rope": 2.6079999282956125e-05,
              "kv_append": 9.625600278377533e-05,
              "attention_op": 9.324800223112106e-05,
              "o_proj": 5.6671999394893644e-05
            },
            "ffn": 0.0002428160011768341
          },
          "layer_1": {
            "total": 0.0007756159901618957,
            "attention": {
              "total": 0.0004869759976863861,
              "qkv_proj": 0.0001221119984984398,
              "rope": 2.486399933695793e-05,
              "kv_append": 9.004800021648407e-05,
              "attention_op": 9.363199770450592e-05,
              "o_proj": 5.411199852824211e-05
            },
            "ffn": 0.00024291199445724488
          },
          "layer_2": {
            "total": 0.0007635520100593567,
            "attention": {
              "total": 0.0004787200093269348,
              "qkv_proj": 0.0001221119984984398,
              "rope": 2.4800000712275504e-05,
              "kv_append": 8.611200004816055e-05,
              "attention_op": 9.110400080680848e-05,
              "o_proj": 5.433600023388863e-05
            },
            "ffn": 0.00024086399376392365
          },
          "layer_3": {
            "total": 0.0007649919986724853,
            "attention": {
              "total": 0.0004798080027103424,
              "qkv_proj": 0.0001207680031657219,
              "rope": 2.502400055527687e-05,
              "kv_append": 8.716800063848495e-05,
              "attention_op": 9.161599725484848e-05,
              "o_proj": 5.465599894523621e-05
            },
            "ffn": 0.00024006399512290955
          },
          "layer_4": {
            "total": 0.0007602239847183227,
            "attention": {
              "total": 0.00047603198885917664,
              "qkv_proj": 0.00011993599683046341,
              "rope": 2.4960000067949296e-05,
              "kv_append": 8.502399921417236e-05,
              "attention_op": 9.324800223112106e-05,
              "o_proj": 5.356800183653831e-05
            },
            "ffn": 0.000240447998046875
          },
          "layer_5": {
            "total": 0.0007694720029830933,
            "attention": {
              "total": 0.00048345598578453065,
              "qkv_proj": 0.0001308480054140091,
              "rope": 2.473600022494793e-05,
              "kv_append": 8.38719978928566e-05,
              "attention_op": 9.167999774217606e-05,
              "o_proj": 5.356800183653831e-05
            },
            "ffn": 0.00024265600740909577
          },
          "layer_6": {
            "total": 0.0007550719976425171,
            "attention": {
              "total": 0.000470335990190506,
              "qkv_proj": 0.00011814399808645249,
              "rope": 2.502400055527687e-05,
              "kv_append": 8.406399935483933e-05,
              "attention_op": 9.145600348711014e-05,
              "o_proj": 5.3472001105546954e-05
            },
            "ffn": 0.00024128000438213348
          },
          "layer_7": {
            "total": 0.0007552000284194947,
            "attention": {
              "total": 0.0004724160134792328,
              "qkv_proj": 0.00012019199877977372,
              "rope": 2.4768000468611716e-05,
              "kv_append": 8.310399949550629e-05,
              "attention_op": 9.171199798583985e-05,
              "o_proj": 5.404800176620483e-05
            },
            "ffn": 0.00023929600417613983
          },
          "layer_8": {
            "total": 0.0007727360129356385,
            "attention": {
              "total": 0.0004899840056896209,
              "qkv_proj": 0.00011974400281906128,
              "rope": 2.4927999824285508e-05,
              "kv_append": 8.646400272846222e-05,
              "attention_op": 9.062399715185165e-05,
              "o_proj": 5.385600030422211e-05
            },
            "ffn": 0.00023926399648189546
          },
          "layer_9": {
            "total": 0.0007714880108833313,
            "attention": {
              "total": 0.00048531201481819155,
              "qkv_proj": 0.00011884800344705582,
              "rope": 2.457600086927414e-05,
              "kv_append": 8.377599716186524e-05,
              "attention_op": 9.10400003194809e-05,
              "o_proj": 5.728000029921532e-05
            },
            "ffn": 0.00024166400730609895
          },
          "layer_10": {
            "total": 0.0007617920041084289,
            "attention": {
              "total": 0.0004768959879875183,
              "qkv_proj": 0.00012041600048542022,
              "rope": 2.5439999997615813e-05,
              "kv_append": 8.425600081682205e-05,
              "attention_op": 9.247999638319015e-05,
              "o_proj": 5.44000007212162e-05
            },
            "ffn": 0.00024051199853420256
          },
          "layer_11": {
            "total": 0.0007542080283164978,
            "attention": {
              "total": 0.00047049599885940553,
              "qkv_proj": 0.00011865600198507309,
              "rope": 2.457600086927414e-05,
              "kv_append": 8.128000050783158e-05,
              "attention_op": 9.219200164079666e-05,
              "o_proj": 5.452800169587135e-05
            },
            "ffn": 0.0002399359941482544
          },
          "layer_12": {
            "total": 0.0007559040188789368,
            "attention": {
              "total": 0.00047065600752830503,
              "qkv_proj": 0.00011958400160074234,
              "rope": 2.489599958062172e-05,
              "kv_append": 8.175999671220779e-05,
              "attention_op": 9.171199798583985e-05,
              "o_proj": 5.363199859857559e-05
            },
            "ffn": 0.0002417919933795929
          },
          "layer_13": {
            "total": 0.0007536320090293884,
            "attention": {
              "total": 0.00046889600157737734,
              "qkv_proj": 0.00011817599833011627,
              "rope": 2.4320000782608984e-05,
              "kv_append": 8.118399977684021e-05,
              "attention_op": 9.120000153779983e-05,
              "o_proj": 5.363199859857559e-05
            },
            "ffn": 0.0002396800071001053
          },
          "layer_14": {
            "total": 0.0007531200051307678,
            "attention": {
              "total": 0.0004683839976787567,
              "qkv_proj": 0.00011971200257539749,
              "rope": 2.5119999423623085e-05,
              "kv_append": 8.032000064849854e-05,
              "attention_op": 9.081599861383438e-05,
              "o_proj": 5.3279999643564224e-05
            },
            "ffn": 0.00024086399376392365
          },
          "layer_15": {
            "total": 0.0007672640085220337,
            "attention": {
              "total": 0.0004848960041999817,
              "qkv_proj": 0.00011903999745845795,
              "rope": 2.502400055527687e-05,
              "kv_append": 9.148799628019333e-05,
              "attention_op": 9.452799707651139e-05,
              "o_proj": 5.4239999502897264e-05
            },
            "ffn": 0.00023843200504779815
          },
          "layer_16": {
            "total": 0.0007576000094413757,
            "attention": {
              "total": 0.0004718720018863678,
              "qkv_proj": 0.00011881600320339203,
              "rope": 2.5696000084280967e-05,
              "kv_append": 8.287999778985977e-05,
              "attention_op": 9.187199920415879e-05,
              "o_proj": 5.379199981689453e-05
            },
            "ffn": 0.00024172799289226533
          },
          "layer_17": {
            "total": 0.0007800319790840149,
            "attention": {
              "total": 0.0004950720071792603,
              "qkv_proj": 0.00011779200285673141,
              "rope": 2.5056000798940658e-05,
              "kv_append": 0.00010896000266075134,
              "attention_op": 9.081599861383438e-05,
              "o_proj": 5.270399898290634e-05
            },
            "ffn": 0.00024140800535678864
          },
          "layer_18": {
            "total": 0.0007567359805107117,
            "attention": {
              "total": 0.00047043201327323913,
              "qkv_proj": 0.00011958400160074234,
              "rope": 2.5151999667286874e-05,
              "kv_append": 8.275199681520462e-05,
              "attention_op": 9.136000275611877e-05,
              "o_proj": 5.3727999329566956e-05
            },
            "ffn": 0.0002428479939699173
          },
          "layer_19": {
            "total": 0.0007496640086174011,
            "attention": {
              "total": 0.0004671359956264496,
              "qkv_proj": 0.000118367999792099,
              "rope": 2.4224000051617622e-05,
              "kv_append": 8.111999928951264e-05,
              "attention_op": 9.113600105047225e-05,
              "o_proj": 5.4719999432563783e-05
            },
            "ffn": 0.00023894399404525757
          },
          "layer_20": {
            "total": 0.0007861440181732178,
            "attention": {
              "total": 0.0005025280117988587,
              "qkv_proj": 0.00014403200149536134,
              "rope": 2.5216000154614447e-05,
              "kv_append": 8.076799660921096e-05,
              "attention_op": 9.932799637317657e-05,
              "o_proj": 5.5456001311540604e-05
            },
            "ffn": 0.00024035200476646423
          },
          "layer_21": {
            "total": 0.0007821440100669861,
            "attention": {
              "total": 0.0004974719882011413,
              "qkv_proj": 0.00014643199741840363,
              "rope": 2.5151999667286874e-05,
              "kv_append": 8.070400357246399e-05,
              "attention_op": 9.171199798583985e-05,
              "o_proj": 5.430399999022484e-05
            },
            "ffn": 0.0002401600033044815
          },
          "layer_22": {
            "total": 0.0007524799704551697,
            "attention": {
              "total": 0.0004689280092716217,
              "qkv_proj": 0.00012038400024175644,
              "rope": 2.425600029528141e-05,
              "kv_append": 8.01599994301796e-05,
              "attention_op": 9.10400003194809e-05,
              "o_proj": 5.4239999502897264e-05
            },
            "ffn": 0.0002396160066127777
          },
          "layer_23": {
            "total": 0.000776639997959137,
            "attention": {
              "total": 0.0004929279983043671,
              "qkv_proj": 0.00011715199798345566,
              "rope": 2.4768000468611716e-05,
              "kv_append": 9.66079980134964e-05,
              "attention_op": 9.180799871683121e-05,
              "o_proj": 5.3504001349210736e-05
            },
            "ffn": 0.00023849600553512573
          },
          "layer_24": {
            "total": 0.0007566080093383789,
            "attention": {
              "total": 0.00047206398844718933,
              "qkv_proj": 0.00011801599711179733,
              "rope": 2.611199952661991e-05,
              "kv_append": 8.367999643087387e-05,
              "attention_op": 9.139200299978256e-05,
              "o_proj": 5.427199974656105e-05
            },
            "ffn": 0.00024102400243282318
          },
          "layer_25": {
            "total": 0.0007652159929275512,
            "attention": {
              "total": 0.00047942399978637693,
              "qkv_proj": 0.00011776000261306762,
              "rope": 2.5056000798940658e-05,
              "kv_append": 8.28159973025322e-05,
              "attention_op": 9.091199934482575e-05,
              "o_proj": 6.37120008468628e-05
            },
            "ffn": 0.00024147200584411621
          },
          "layer_26": {
            "total": 0.0007541760206222534,
            "attention": {
              "total": 0.0004705600142478943,
              "qkv_proj": 0.00011868800222873687,
              "rope": 2.4960000067949296e-05,
              "kv_append": 8.374399691820145e-05,
              "attention_op": 9.04960036277771e-05,
              "o_proj": 5.3279999643564224e-05
            },
            "ffn": 0.00024003200232982635
          },
          "layer_27": {
            "total": 0.0007569599747657776,
            "attention": {
              "total": 0.0004721280038356781,
              "qkv_proj": 0.0001191679984331131,
              "rope": 2.438399940729141e-05,
              "kv_append": 8.191999793052673e-05,
              "attention_op": 9.276799857616425e-05,
              "o_proj": 5.4464001208543776e-05
            },
            "ffn": 0.00024025599658489228
          },
          "layer_28": {
            "total": 0.0007516160011291504,
            "attention": {
              "total": 0.0004666880071163177,
              "qkv_proj": 0.0001170239970088005,
              "rope": 2.4671999737620354e-05,
              "kv_append": 8.137600123882294e-05,
              "attention_op": 9.164799749851227e-05,
              "o_proj": 5.35999983549118e-05
            },
            "ffn": 0.0002417919933795929
          },
          "layer_29": {
            "total": 0.0007602559924125671,
            "attention": {
              "total": 0.0004747520089149475,
              "qkv_proj": 0.00011932799965143204,
              "rope": 2.4447999894618988e-05,
              "kv_append": 8.585599809885026e-05,
              "attention_op": 9.036800265312194e-05,
              "o_proj": 5.44000007212162e-05
            },
            "ffn": 0.0002415039986371994
          },
          "layer_30": {
            "total": 0.0007760319709777833,
            "attention": {
              "total": 0.00047071999311447144,
              "qkv_proj": 0.00011865600198507309,
              "rope": 2.473600022494793e-05,
              "kv_append": 8.30719992518425e-05,
              "attention_op": 9.081599861383438e-05,
              "o_proj": 5.417599901556969e-05
            },
            "ffn": 0.0002508479952812195
          },
          "layer_31": {
            "total": 0.0007874240279197693,
            "attention": {
              "total": 0.0005012159943580627,
              "qkv_proj": 0.00011820799857378006,
              "rope": 2.489599958062172e-05,
              "kv_append": 9.139200299978256e-05,
              "attention_op": 9.513600170612335e-05,
              "o_proj": 5.462399870157242e-05
            },
            "ffn": 0.00024163199961185454
          }
        }
      },
      "lm_head": 0.00048822399973869323
    },
    "longest_op": "lm_head",
    "longest_op_time": 0.00048822399973869323
  },
  {
    "decode_length": 64,
    "log_decode_length": 6.0,
    "prefill_time": 0.7419672012329102,
    "decode_time": 1.7054634094238281,
    "total_time": 2.4474306106567383,
    "prefill_op_times": {
      "input_preparation": 0.0002595199942588806,
      "kv_cache_allocation": 0.0006288319826126098,
      "flashinfer_planning": 0.00025993600487709043,
      "embedding_lookup": 0.00045916798710823057,
      "transformer_layers": {
        "layer_time": 0.6507617874145507,
        "attention_time": 0.16813542366027825,
        "ffn_time": 0.48056204891204823,
        "detailed_layers": {
          "layer_0": {
            "total": 0.019357696533203125,
            "attention": {
              "total": 0.0050854082107543944,
              "qkv_proj": 0.0025694398880004884,
              "rope": 0.00021558399498462677,
              "kv_append": 0.00020764799416065217,
              "attention_op": 0.0006007680296897888,
              "o_proj": 0.001382207989692688
            },
            "ffn": 0.014212991714477539
          },
          "layer_1": {
            "total": 0.01935228729248047,
            "attention": {
              "total": 0.005051328182220459,
              "qkv_proj": 0.0025437440872192385,
              "rope": 0.00021011200547218324,
              "kv_append": 0.00019068799912929534,
              "attention_op": 0.000597536027431488,
              "o_proj": 0.0013819520473480225
            },
            "ffn": 0.014239551544189454
          },
          "layer_2": {
            "total": 0.019556928634643554,
            "attention": {
              "total": 0.005094687938690185,
              "qkv_proj": 0.002582047939300537,
              "rope": 0.0002104959934949875,
              "kv_append": 0.0001828480064868927,
              "attention_op": 0.0006082559823989868,
              "o_proj": 0.0013979519605636596
            },
            "ffn": 0.014400575637817383
          },
          "layer_3": {
            "total": 0.019566879272460938,
            "attention": {
              "total": 0.005102335929870605,
              "qkv_proj": 0.00257475209236145,
              "rope": 0.00021139200031757355,
              "kv_append": 0.00018352000415325164,
              "attention_op": 0.0006244800090789795,
              "o_proj": 0.0013975679874420166
            },
            "ffn": 0.01440060806274414
          },
          "layer_4": {
            "total": 0.020003711700439453,
            "attention": {
              "total": 0.005138783931732178,
              "qkv_proj": 0.0025773439407348634,
              "rope": 0.000215488001704216,
              "kv_append": 0.00019299200177192688,
              "attention_op": 0.0006279360055923462,
              "o_proj": 0.0014032000303268433
            },
            "ffn": 0.014803104400634766
          },
          "layer_5": {
            "total": 0.020369312286376954,
            "attention": {
              "total": 0.005260447978973389,
              "qkv_proj": 0.0026374399662017823,
              "rope": 0.00021420800685882567,
              "kv_append": 0.00019215999543666838,
              "attention_op": 0.0006678079962730408,
              "o_proj": 0.0014309120178222657
            },
            "ffn": 0.01504643154144287
          },
          "layer_6": {
            "total": 0.020262367248535158,
            "attention": {
              "total": 0.005227007865905762,
              "qkv_proj": 0.00262227201461792,
              "rope": 0.00021596799790859223,
              "kv_append": 0.00018688000738620758,
              "attention_op": 0.0006634560227394104,
              "o_proj": 0.0014216320514678954
            },
            "ffn": 0.014974111557006837
          },
          "layer_7": {
            "total": 0.020433855056762696,
            "attention": {
              "total": 0.005245920181274414,
              "qkv_proj": 0.002628704071044922,
              "rope": 0.00021456000208854676,
              "kv_append": 0.00018694399297237396,
              "attention_op": 0.0006711680293083191,
              "o_proj": 0.001431488037109375
            },
            "ffn": 0.01512441635131836
          },
          "layer_8": {
            "total": 0.02024412727355957,
            "attention": {
              "total": 0.005220096111297607,
              "qkv_proj": 0.0026254079341888428,
              "rope": 0.00021212799847126007,
              "kv_append": 0.0001871040016412735,
              "attention_op": 0.0006589760184288025,
              "o_proj": 0.0014220160245895386
            },
            "ffn": 0.014964447975158692
          },
          "layer_9": {
            "total": 0.020301023483276368,
            "attention": {
              "total": 0.005235424041748047,
              "qkv_proj": 0.0026299200057983397,
              "rope": 0.0002115200012922287,
              "kv_append": 0.00018835200369358063,
              "attention_op": 0.0006624959707260132,
              "o_proj": 0.0014223359823226929
            },
            "ffn": 0.015005311965942382
          },
          "layer_10": {
            "total": 0.020305055618286133,
            "attention": {
              "total": 0.0052285118103027346,
              "qkv_proj": 0.0026264638900756836,
              "rope": 0.0002136960029602051,
              "kv_append": 0.00018764799833297728,
              "attention_op": 0.0006649280190467834,
              "o_proj": 0.0014234559535980225
            },
            "ffn": 0.015015904426574706
          },
          "layer_11": {
            "total": 0.020327775955200196,
            "attention": {
              "total": 0.005230847835540771,
              "qkv_proj": 0.002635807991027832,
              "rope": 0.00021212799847126007,
              "kv_append": 0.00018563200533390045,
              "attention_op": 0.0006625279784202576,
              "o_proj": 0.0014207359552383422
            },
            "ffn": 0.0150349760055542
          },
          "layer_12": {
            "total": 0.020255136489868163,
            "attention": {
              "total": 0.0052368960380554195,
              "qkv_proj": 0.0026355199813842775,
              "rope": 0.00021180799603462219,
              "kv_append": 0.00018707199394702912,
              "attention_op": 0.0006594560146331787,
              "o_proj": 0.0014265600442886352
            },
            "ffn": 0.014956064224243164
          },
          "layer_13": {
            "total": 0.020147487640380858,
            "attention": {
              "total": 0.005213600158691406,
              "qkv_proj": 0.0026138238906860353,
              "rope": 0.00021420800685882567,
              "kv_append": 0.00019875200092792512,
              "attention_op": 0.0006535040140151977,
              "o_proj": 0.0014105919599533081
            },
            "ffn": 0.01487168025970459
          },
          "layer_14": {
            "total": 0.020357696533203126,
            "attention": {
              "total": 0.00525871992111206,
              "qkv_proj": 0.002648736000061035,
              "rope": 0.00021235199272632598,
              "kv_append": 0.00018617600202560424,
              "attention_op": 0.0006689599752426147,
              "o_proj": 0.0014278080463409424
            },
            "ffn": 0.015036831855773926
          },
          "layer_15": {
            "total": 0.020266080856323244,
            "attention": {
              "total": 0.005204288005828858,
              "qkv_proj": 0.0026233599185943603,
              "rope": 0.00021216000616550444,
              "kv_append": 0.00018665599822998048,
              "attention_op": 0.0006572800278663635,
              "o_proj": 0.0014143359661102294
            },
            "ffn": 0.014996864318847657
          },
          "layer_16": {
            "total": 0.02043903923034668,
            "attention": {
              "total": 0.005269055843353272,
              "qkv_proj": 0.0026493439674377442,
              "rope": 0.00021382400393486024,
              "kv_append": 0.00019017599523067476,
              "attention_op": 0.0006681280136108398,
              "o_proj": 0.001431488037109375
            },
            "ffn": 0.015105600357055665
          },
          "layer_17": {
            "total": 0.020155296325683594,
            "attention": {
              "total": 0.005211840152740479,
              "qkv_proj": 0.0026204800605773926,
              "rope": 0.0002152319997549057,
              "kv_append": 0.0001865600049495697,
              "attention_op": 0.000657535970211029,
              "o_proj": 0.0014175679683685303
            },
            "ffn": 0.014880352020263672
          },
          "layer_18": {
            "total": 0.0200600643157959,
            "attention": {
              "total": 0.0051840639114379885,
              "qkv_proj": 0.0026071679592132566,
              "rope": 0.000213919997215271,
              "kv_append": 0.00018812799453735352,
              "attention_op": 0.000651968002319336,
              "o_proj": 0.0014071999788284302
            },
            "ffn": 0.01481488037109375
          },
          "layer_19": {
            "total": 0.0201910400390625,
            "attention": {
              "total": 0.005186111927032471,
              "qkv_proj": 0.0026141119003295897,
              "rope": 0.00021235199272632598,
              "kv_append": 0.0001851840019226074,
              "attention_op": 0.0006508479714393615,
              "o_proj": 0.001412511944770813
            },
            "ffn": 0.014942943572998047
          },
          "layer_20": {
            "total": 0.020405183792114256,
            "attention": {
              "total": 0.005258815765380859,
              "qkv_proj": 0.00264355206489563,
              "rope": 0.00021324799954891205,
              "kv_append": 0.00019625599682331085,
              "attention_op": 0.0006649280190467834,
              "o_proj": 0.0014268800020217896
            },
            "ffn": 0.015082655906677246
          },
          "layer_21": {
            "total": 0.020400928497314452,
            "attention": {
              "total": 0.005254784107208252,
              "qkv_proj": 0.002646656036376953,
              "rope": 0.00021468800306320192,
              "kv_append": 0.00018464000523090362,
              "attention_op": 0.0006660159826278687,
              "o_proj": 0.0014313919544219971
            },
            "ffn": 0.015083040237426758
          },
          "layer_22": {
            "total": 0.02079475212097168,
            "attention": {
              "total": 0.00536902379989624,
              "qkv_proj": 0.00270249605178833,
              "rope": 0.00021513600647449493,
              "kv_append": 0.000191648006439209,
              "attention_op": 0.0006812160015106201,
              "o_proj": 0.0014658880233764649
            },
            "ffn": 0.015363903999328613
          },
          "layer_23": {
            "total": 0.020641151428222655,
            "attention": {
              "total": 0.0053095040321350095,
              "qkv_proj": 0.0026766719818115234,
              "rope": 0.00021241599321365355,
              "kv_append": 0.00018400000035762788,
              "attention_op": 0.0006766080260276795,
              "o_proj": 0.0014456000328063965
            },
            "ffn": 0.015270336151123047
          },
          "layer_24": {
            "total": 0.020785343170166014,
            "attention": {
              "total": 0.005305535793304443,
              "qkv_proj": 0.0026704959869384764,
              "rope": 0.0002125760018825531,
              "kv_append": 0.0001839040070772171,
              "attention_op": 0.0006747199892997742,
              "o_proj": 0.0014472960233688356
            },
            "ffn": 0.015417471885681152
          },
          "layer_25": {
            "total": 0.020953855514526366,
            "attention": {
              "total": 0.005390463829040527,
              "qkv_proj": 0.0027111361026763915,
              "rope": 0.00022441600263118744,
              "kv_append": 0.00018643200397491455,
              "attention_op": 0.0006856639981269836,
              "o_proj": 0.0014711359739303588
            },
            "ffn": 0.015429280281066894
          },
          "layer_26": {
            "total": 0.02106675148010254,
            "attention": {
              "total": 0.005595392227172852,
              "qkv_proj": 0.0027067520618438722,
              "rope": 0.00024003200232982635,
              "kv_append": 0.0003511680066585541,
              "attention_op": 0.000711903989315033,
              "o_proj": 0.0014663039445877075
            },
            "ffn": 0.015408351898193359
          },
          "layer_27": {
            "total": 0.020797567367553713,
            "attention": {
              "total": 0.005311552047729492,
              "qkv_proj": 0.0026787519454956055,
              "rope": 0.00021347199380397796,
              "kv_append": 0.00018995200097560882,
              "attention_op": 0.000673632025718689,
              "o_proj": 0.001441696047782898
            },
            "ffn": 0.015422880172729492
          },
          "layer_28": {
            "total": 0.020773088455200196,
            "attention": {
              "total": 0.005382815837860108,
              "qkv_proj": 0.002711711883544922,
              "rope": 0.00021331200003623963,
              "kv_append": 0.0001902720034122467,
              "attention_op": 0.0006855360269546509,
              "o_proj": 0.001466048002243042
            },
            "ffn": 0.015327808380126953
          },
          "layer_29": {
            "total": 0.02073958396911621,
            "attention": {
              "total": 0.005340320110321045,
              "qkv_proj": 0.002681823968887329,
              "rope": 0.00021568000316619874,
              "kv_append": 0.00019424000382423402,
              "attention_op": 0.0006778879761695862,
              "o_proj": 0.0014511040449142457
            },
            "ffn": 0.01533513641357422
          },
          "layer_30": {
            "total": 0.020753599166870116,
            "attention": {
              "total": 0.0053517441749572755,
              "qkv_proj": 0.002676512002944946,
              "rope": 0.00021619200706481933,
              "kv_append": 0.00020774400234222412,
              "attention_op": 0.0006832640171051025,
              "o_proj": 0.0014523839950561523
            },
            "ffn": 0.015339903831481934
          },
          "layer_31": {
            "total": 0.020697120666503907,
            "attention": {
              "total": 0.005380095958709717,
              "qkv_proj": 0.0026870079040527345,
              "rope": 0.0002165759950876236,
              "kv_append": 0.00022643199563026427,
              "attention_op": 0.000684224009513855,
              "o_proj": 0.0014517439603805543
            },
            "ffn": 0.015253631591796876
          }
        }
      },
      "lm_head": 0.044547008514404296
    },
    "last_decode_op_times": {
      "input_preparation": 0.00020057600736618042,
      "kv_cache_allocation": 0.00033481600880622863,
      "flashinfer_planning": 0.00013686400651931763,
      "embedding_lookup": 3.033600002527237e-05,
      "transformer_layers": {
        "layer_time": 0.02481311982870102,
        "attention_time": 0.015719391971826556,
        "ffn_time": 0.007696287974715234,
        "detailed_layers": {
          "layer_0": {
            "total": 0.0008180480003356933,
            "attention": {
              "total": 0.0005323519706726074,
              "qkv_proj": 0.00014127999544143676,
              "rope": 2.6208000257611275e-05,
              "kv_append": 9.350399672985077e-05,
              "attention_op": 0.00010847999900579453,
              "o_proj": 5.9744000434875486e-05
            },
            "ffn": 0.00024252800643444062
          },
          "layer_1": {
            "total": 0.0007859519720077514,
            "attention": {
              "total": 0.0005006399750709533,
              "qkv_proj": 0.00012252800166606903,
              "rope": 2.5567999109625817e-05,
              "kv_append": 8.65280032157898e-05,
              "attention_op": 0.00010896000266075134,
              "o_proj": 5.4944001138210295e-05
            },
            "ffn": 0.00024137599766254424
          },
          "layer_2": {
            "total": 0.0007790079712867736,
            "attention": {
              "total": 0.0004924159944057465,
              "qkv_proj": 0.00011897599697113037,
              "rope": 2.5119999423623085e-05,
              "kv_append": 8.470399677753449e-05,
              "attention_op": 0.00010889600217342376,
              "o_proj": 5.436800047755242e-05
            },
            "ffn": 0.0002425599992275238
          },
          "layer_3": {
            "total": 0.0007778559923171997,
            "attention": {
              "total": 0.0004929600059986114,
              "qkv_proj": 0.00012121599912643432,
              "rope": 2.4960000067949296e-05,
              "kv_append": 8.326400071382522e-05,
              "attention_op": 0.00010793600231409072,
              "o_proj": 5.510399863123894e-05
            },
            "ffn": 0.00024006399512290955
          },
          "layer_4": {
            "total": 0.0007686399817466735,
            "attention": {
              "total": 0.0004861760139465332,
              "qkv_proj": 0.0001181119978427887,
              "rope": 2.4480000138282777e-05,
              "kv_append": 8.297599852085114e-05,
              "attention_op": 0.00010704000294208526,
              "o_proj": 5.4239999502897264e-05
            },
            "ffn": 0.00023820799589157105
          },
          "layer_5": {
            "total": 0.0007842239737510681,
            "attention": {
              "total": 0.0005019519925117493,
              "qkv_proj": 0.00011817599833011627,
              "rope": 2.5439999997615813e-05,
              "kv_append": 8.275199681520462e-05,
              "attention_op": 0.00010908800363540649,
              "o_proj": 6.643199920654297e-05
            },
            "ffn": 0.00023887999355793
          },
          "layer_6": {
            "total": 0.0007720320224761963,
            "attention": {
              "total": 0.0004884159862995148,
              "qkv_proj": 0.00011894399672746658,
              "rope": 2.502400055527687e-05,
              "kv_append": 8.300799876451493e-05,
              "attention_op": 0.00010751999914646149,
              "o_proj": 5.38880005478859e-05
            },
            "ffn": 0.00023951999843120576
          },
          "layer_7": {
            "total": 0.0007695680260658265,
            "attention": {
              "total": 0.00048582398891448977,
              "qkv_proj": 0.0001191679984331131,
              "rope": 2.473600022494793e-05,
              "kv_append": 8.204799890518189e-05,
              "attention_op": 0.00010796800255775451,
              "o_proj": 5.385600030422211e-05
            },
            "ffn": 0.00023996800184249877
          },
          "layer_8": {
            "total": 0.0007656959891319275,
            "attention": {
              "total": 0.0004819200038909912,
              "qkv_proj": 0.00011715199798345566,
              "rope": 2.4159999564290046e-05,
              "kv_append": 8.076799660921096e-05,
              "attention_op": 0.00010771200060844422,
              "o_proj": 5.337600037455559e-05
            },
            "ffn": 0.0002404160052537918
          },
          "layer_9": {
            "total": 0.0007662720084190369,
            "attention": {
              "total": 0.0004830400049686432,
              "qkv_proj": 0.00011884800344705582,
              "rope": 2.454400062561035e-05,
              "kv_append": 7.93600007891655e-05,
              "attention_op": 0.00010896000266075134,
              "o_proj": 5.35999983549118e-05
            },
            "ffn": 0.000240447998046875
          },
          "layer_10": {
            "total": 0.0008106880187988281,
            "attention": {
              "total": 0.000525983989238739,
              "qkv_proj": 0.00011747200042009354,
              "rope": 2.499200031161308e-05,
              "kv_append": 8.137600123882294e-05,
              "attention_op": 0.00010547199845314026,
              "o_proj": 9.164799749851227e-05
            },
            "ffn": 0.00024163199961185454
          },
          "layer_11": {
            "total": 0.0007669119834899902,
            "attention": {
              "total": 0.00048438400030136107,
              "qkv_proj": 0.00011872000247240066,
              "rope": 2.4831999093294143e-05,
              "kv_append": 8.064000308513641e-05,
              "attention_op": 0.00010723199695348739,
              "o_proj": 5.369599908590317e-05
            },
            "ffn": 0.00023926399648189546
          },
          "layer_12": {
            "total": 0.0007669119834899902,
            "attention": {
              "total": 0.00048368000984191895,
              "qkv_proj": 0.00011843200027942658,
              "rope": 2.4831999093294143e-05,
              "kv_append": 8.064000308513641e-05,
              "attention_op": 0.00010796800255775451,
              "o_proj": 5.318399891257286e-05
            },
            "ffn": 0.0002396479994058609
          },
          "layer_13": {
            "total": 0.0007675520181655884,
            "attention": {
              "total": 0.0004839999973773956,
              "qkv_proj": 0.00011939200013875961,
              "rope": 2.4960000067949296e-05,
              "kv_append": 8.012799918651581e-05,
              "attention_op": 0.00010697600245475768,
              "o_proj": 5.379199981689453e-05
            },
            "ffn": 0.00024051199853420256
          },
          "layer_14": {
            "total": 0.0007919359803199768,
            "attention": {
              "total": 0.000506816029548645,
              "qkv_proj": 0.00011859200149774551,
              "rope": 2.489599958062172e-05,
              "kv_append": 0.00010444799810647964,
              "attention_op": 0.00010761599987745285,
              "o_proj": 5.3279999643564224e-05
            },
            "ffn": 0.00024172799289226533
          },
          "layer_15": {
            "total": 0.0008038399815559387,
            "attention": {
              "total": 0.0005195519924163819,
              "qkv_proj": 0.00011798399686813354,
              "rope": 2.499200031161308e-05,
              "kv_append": 8.060800284147262e-05,
              "attention_op": 0.00010803200304508209,
              "o_proj": 8.640000224113465e-05
            },
            "ffn": 0.00024102400243282318
          },
          "layer_16": {
            "total": 0.0007676799893379211,
            "attention": {
              "total": 0.00048412799835205076,
              "qkv_proj": 0.00011798399686813354,
              "rope": 2.4480000138282777e-05,
              "kv_append": 8.14720019698143e-05,
              "attention_op": 0.00010716799646615982,
              "o_proj": 5.3984001278877256e-05
            },
            "ffn": 0.0002393600046634674
          },
          "layer_17": {
            "total": 0.0007713599801063537,
            "attention": {
              "total": 0.0004878079891204834,
              "qkv_proj": 0.00011823999881744385,
              "rope": 2.5216000154614447e-05,
              "kv_append": 8.14720019698143e-05,
              "attention_op": 0.00010764800012111664,
              "o_proj": 5.465599894523621e-05
            },
            "ffn": 0.0002401600033044815
          },
          "layer_18": {
            "total": 0.000766431987285614,
            "attention": {
              "total": 0.00048134401440620423,
              "qkv_proj": 0.00011648000031709671,
              "rope": 2.4351999163627623e-05,
              "kv_append": 8.124800026416779e-05,
              "attention_op": 0.00010662399977445603,
              "o_proj": 5.3472001105546954e-05
            },
            "ffn": 0.0002412479966878891
          },
          "layer_19": {
            "total": 0.0007663040161132813,
            "attention": {
              "total": 0.00048393601179122926,
              "qkv_proj": 0.00011820799857378006,
              "rope": 2.4703999981284142e-05,
              "kv_append": 8.140800148248673e-05,
              "attention_op": 0.00010735999792814255,
              "o_proj": 5.38880005478859e-05
            },
            "ffn": 0.00023919999599456788
          },
          "layer_20": {
            "total": 0.0007852159738540649,
            "attention": {
              "total": 0.0004998080134391785,
              "qkv_proj": 0.00011840000003576279,
              "rope": 2.42880005389452e-05,
              "kv_append": 8.070400357246399e-05,
              "attention_op": 0.00010847999900579453,
              "o_proj": 6.47360011935234e-05
            },
            "ffn": 0.00024031999707221986
          },
          "layer_21": {
            "total": 0.0007718399763107299,
            "attention": {
              "total": 0.0004883520007133484,
              "qkv_proj": 0.000118367999792099,
              "rope": 2.486399933695793e-05,
              "kv_append": 8.320000022649766e-05,
              "attention_op": 0.00010860799998044968,
              "o_proj": 5.4464001208543776e-05
            },
            "ffn": 0.0002393600046634674
          },
          "layer_22": {
            "total": 0.0007663999795913697,
            "attention": {
              "total": 0.0004827840030193329,
              "qkv_proj": 0.00011852800101041793,
              "rope": 2.4447999894618988e-05,
              "kv_append": 8.009599894285202e-05,
              "attention_op": 0.00010646399855613708,
              "o_proj": 5.385600030422211e-05
            },
            "ffn": 0.00023987199366092682
          },
          "layer_23": {
            "total": 0.0007649599909782409,
            "attention": {
              "total": 0.00048182401061058045,
              "qkv_proj": 0.0001178240031003952,
              "rope": 2.4831999093294143e-05,
              "kv_append": 8.060800284147262e-05,
              "attention_op": 0.00010585600137710572,
              "o_proj": 5.3984001278877256e-05
            },
            "ffn": 0.0002396800071001053
          },
          "layer_24": {
            "total": 0.0007650240063667297,
            "attention": {
              "total": 0.000481471985578537,
              "qkv_proj": 0.0001170239970088005,
              "rope": 2.5439999997615813e-05,
              "kv_append": 8.20159986615181e-05,
              "attention_op": 0.00010595200210809708,
              "o_proj": 5.321599915623665e-05
            },
            "ffn": 0.00023955200612545014
          },
          "layer_25": {
            "total": 0.0007774080038070679,
            "attention": {
              "total": 0.0004907520115375518,
              "qkv_proj": 0.00011833599954843522,
              "rope": 2.502400055527687e-05,
              "kv_append": 8.1727996468544e-05,
              "attention_op": 0.00010745599865913391,
              "o_proj": 5.939200147986412e-05
            },
            "ffn": 0.00024291199445724488
          },
          "layer_26": {
            "total": 0.0007688000202178955,
            "attention": {
              "total": 0.0004848639965057373,
              "qkv_proj": 0.00011881600320339203,
              "rope": 2.5216000154614447e-05,
              "kv_append": 8.220800012350083e-05,
              "attention_op": 0.00010723199695348739,
              "o_proj": 5.2992001175880435e-05
            },
            "ffn": 0.00024038399755954744
          },
          "layer_27": {
            "total": 0.0007708799839019775,
            "attention": {
              "total": 0.0004870719909667969,
              "qkv_proj": 0.00011926399916410447,
              "rope": 2.5216000154614447e-05,
              "kv_append": 8.265600353479385e-05,
              "attention_op": 0.0001080000028014183,
              "o_proj": 5.292800068855286e-05
            },
            "ffn": 0.00023945599794387819
          },
          "layer_28": {
            "total": 0.0007653120160102844,
            "attention": {
              "total": 0.0004852159917354584,
              "qkv_proj": 0.0001173119992017746,
              "rope": 2.4191999807953834e-05,
              "kv_append": 8.259200304746628e-05,
              "attention_op": 0.00010694400221109391,
              "o_proj": 5.44000007212162e-05
            },
            "ffn": 0.00023683199286460876
          },
          "layer_29": {
            "total": 0.0007655360102653503,
            "attention": {
              "total": 0.0004822080135345459,
              "qkv_proj": 0.00011683200299739837,
              "rope": 2.454400062561035e-05,
              "kv_append": 8.048000186681748e-05,
              "attention_op": 0.00010751999914646149,
              "o_proj": 5.38880005478859e-05
            },
            "ffn": 0.00024025599658489228
          },
          "layer_30": {
            "total": 0.0007764160037040711,
            "attention": {
              "total": 0.00048287999629974363,
              "qkv_proj": 0.0001167680025100708,
              "rope": 2.457600086927414e-05,
              "kv_append": 8.188799768686294e-05,
              "attention_op": 0.00010681600123643876,
              "o_proj": 5.38880005478859e-05
            },
            "ffn": 0.00025004801154136655
          },
          "layer_31": {
            "total": 0.0007684159874916076,
            "attention": {
              "total": 0.00048483198881149294,
              "qkv_proj": 0.0001186240017414093,
              "rope": 2.4671999737620354e-05,
              "kv_append": 8.064000308513641e-05,
              "attention_op": 0.00010726399719715118,
              "o_proj": 5.3472001105546954e-05
            },
            "ffn": 0.00023987199366092682
          }
        }
      },
      "lm_head": 0.0004870400130748749
    },
    "longest_op": "lm_head",
    "longest_op_time": 0.0004870400130748749
  },
  {
    "decode_length": 128,
    "log_decode_length": 7.0,
    "prefill_time": 0.7438771724700928,
    "decode_time": 3.456589460372925,
    "total_time": 4.200466632843018,
    "prefill_op_times": {
      "input_preparation": 0.000311167985200882,
      "kv_cache_allocation": 0.0006837120056152344,
      "flashinfer_planning": 0.00027935999631881713,
      "embedding_lookup": 0.00043123200535774233,
      "transformer_layers": {
        "layer_time": 0.6512446708679198,
        "attention_time": 0.16789193534851077,
        "ffn_time": 0.4813390426635743,
        "detailed_layers": {
          "layer_0": {
            "total": 0.01935753631591797,
            "attention": {
              "total": 0.005094687938690185,
              "qkv_proj": 0.002554879903793335,
              "rope": 0.00021395200490951537,
              "kv_append": 0.0002197120040655136,
              "attention_op": 0.0006119679808616639,
              "o_proj": 0.0013835840225219726
            },
            "ffn": 0.014205599784851074
          },
          "layer_1": {
            "total": 0.019327423095703126,
            "attention": {
              "total": 0.00502780818939209,
              "qkv_proj": 0.002544287919998169,
              "rope": 0.0002120960056781769,
              "kv_append": 0.00018544000387191772,
              "attention_op": 0.0005890560150146484,
              "o_proj": 0.0013831039667129516
            },
            "ffn": 0.014241024017333985
          },
          "layer_2": {
            "total": 0.020108831405639647,
            "attention": {
              "total": 0.005097248077392578,
              "qkv_proj": 0.002568831920623779,
              "rope": 0.0002101760059595108,
              "kv_append": 0.00018886399269104004,
              "attention_op": 0.000618336021900177,
              "o_proj": 0.0013979519605636596
            },
            "ffn": 0.014949440002441406
          },
          "layer_3": {
            "total": 0.020219648361206054,
            "attention": {
              "total": 0.005212831974029541,
              "qkv_proj": 0.0026166720390319825,
              "rope": 0.00021456000208854676,
              "kv_append": 0.00018953600525856018,
              "attention_op": 0.0006586560010910035,
              "o_proj": 0.0014191039800643922
            },
            "ffn": 0.014945568084716797
          },
          "layer_4": {
            "total": 0.02021171188354492,
            "attention": {
              "total": 0.005225215911865234,
              "qkv_proj": 0.002619647979736328,
              "rope": 0.00021331200003623963,
              "kv_append": 0.00019827200472354888,
              "attention_op": 0.0006587839722633362,
              "o_proj": 0.0014192639589309692
            },
            "ffn": 0.014927264213562011
          },
          "layer_5": {
            "total": 0.02034883117675781,
            "attention": {
              "total": 0.0051866240501403805,
              "qkv_proj": 0.0026054720878601074,
              "rope": 0.00021328000724315642,
              "kv_append": 0.0001857600063085556,
              "attention_op": 0.0006491519808769226,
              "o_proj": 0.0014190080165863038
            },
            "ffn": 0.015101152420043945
          },
          "layer_6": {
            "total": 0.02071334457397461,
            "attention": {
              "total": 0.005251743793487549,
              "qkv_proj": 0.0026485760211944582,
              "rope": 0.00021318399906158447,
              "kv_append": 0.00018348799645900727,
              "attention_op": 0.0006676160097122192,
              "o_proj": 0.0014257279634475708
            },
            "ffn": 0.015398688316345215
          },
          "layer_7": {
            "total": 0.020776063919067382,
            "attention": {
              "total": 0.0053500161170959475,
              "qkv_proj": 0.002694943904876709,
              "rope": 0.00021529600024223328,
              "kv_append": 0.00018729600310325622,
              "attention_op": 0.0006813759803771973,
              "o_proj": 0.0014520959854125977
            },
            "ffn": 0.015365440368652344
          },
          "layer_8": {
            "total": 0.020786880493164062,
            "attention": {
              "total": 0.005355391979217529,
              "qkv_proj": 0.0026911680698394774,
              "rope": 0.0002128320038318634,
              "kv_append": 0.0001996160000562668,
              "attention_op": 0.0006790720224380493,
              "o_proj": 0.001456671953201294
            },
            "ffn": 0.015368000030517578
          },
          "layer_9": {
            "total": 0.020710975646972656,
            "attention": {
              "total": 0.0053359360694885255,
              "qkv_proj": 0.002683743953704834,
              "rope": 0.00021644799411296844,
              "kv_append": 0.00018838399648666383,
              "attention_op": 0.0006784960031509399,
              "o_proj": 0.0014554879665374756
            },
            "ffn": 0.015314528465270996
          },
          "layer_10": {
            "total": 0.020433088302612305,
            "attention": {
              "total": 0.005265408039093018,
              "qkv_proj": 0.0026591999530792237,
              "rope": 0.00021305599808692932,
              "kv_append": 0.0001820479929447174,
              "attention_op": 0.0006680319905281067,
              "o_proj": 0.0014306880235671997
            },
            "ffn": 0.015105119705200195
          },
          "layer_11": {
            "total": 0.020471296310424804,
            "attention": {
              "total": 0.005265279769897461,
              "qkv_proj": 0.0026453120708465577,
              "rope": 0.00021193599700927734,
              "kv_append": 0.00018406400084495543,
              "attention_op": 0.0006684160232543945,
              "o_proj": 0.0014407039880752564
            },
            "ffn": 0.015143744468688965
          },
          "layer_12": {
            "total": 0.020444671630859376,
            "attention": {
              "total": 0.005262527942657471,
              "qkv_proj": 0.002650912046432495,
              "rope": 0.00021408000588417052,
              "kv_append": 0.0001865919977426529,
              "attention_op": 0.0006669120192527771,
              "o_proj": 0.001429792046546936
            },
            "ffn": 0.015119551658630371
          },
          "layer_13": {
            "total": 0.02045779228210449,
            "attention": {
              "total": 0.0052713918685913085,
              "qkv_proj": 0.0026494081020355226,
              "rope": 0.00021235199272632598,
              "kv_append": 0.0001955520063638687,
              "attention_op": 0.0006687679886817932,
              "o_proj": 0.0014319679737091065
            },
            "ffn": 0.015122400283813477
          },
          "layer_14": {
            "total": 0.02035171127319336,
            "attention": {
              "total": 0.005256768226623535,
              "qkv_proj": 0.0026487679481506346,
              "rope": 0.0002122880071401596,
              "kv_append": 0.00018435199558734894,
              "attention_op": 0.0006679999828338623,
              "o_proj": 0.001431167960166931
            },
            "ffn": 0.015031968116760254
          },
          "layer_15": {
            "total": 0.020455392837524414,
            "attention": {
              "total": 0.005251167774200439,
              "qkv_proj": 0.002646399974822998,
              "rope": 0.00021500800549983977,
              "kv_append": 0.00018214400112628938,
              "attention_op": 0.0006675199866294861,
              "o_proj": 0.0014279999732971192
            },
            "ffn": 0.015117504119873048
          },
          "layer_16": {
            "total": 0.020553600311279296,
            "attention": {
              "total": 0.005368224143981934,
              "qkv_proj": 0.0026576321125030516,
              "rope": 0.00023027199506759643,
              "kv_append": 0.0002443840056657791,
              "attention_op": 0.0006815680265426636,
              "o_proj": 0.0014294079542160035
            },
            "ffn": 0.015120287895202637
          },
          "layer_17": {
            "total": 0.020313312530517578,
            "attention": {
              "total": 0.0052386560440063476,
              "qkv_proj": 0.0026390719413757324,
              "rope": 0.00021491199731826782,
              "kv_append": 0.00018636800348758697,
              "attention_op": 0.0006638399958610535,
              "o_proj": 0.0014204800128936768
            },
            "ffn": 0.015012160301208496
          },
          "layer_18": {
            "total": 0.020317056655883788,
            "attention": {
              "total": 0.005238239765167236,
              "qkv_proj": 0.0026416640281677244,
              "rope": 0.000211776003241539,
              "kv_append": 0.00018675200641155243,
              "attention_op": 0.0006628159880638123,
              "o_proj": 0.0014230400323867799
            },
            "ffn": 0.015013088226318359
          },
          "layer_19": {
            "total": 0.020405727386474608,
            "attention": {
              "total": 0.005240416049957276,
              "qkv_proj": 0.0026317760944366453,
              "rope": 0.00021270400285720826,
              "kv_append": 0.00019462400674819945,
              "attention_op": 0.0006665279865264893,
              "o_proj": 0.001421183943748474
            },
            "ffn": 0.01509939193725586
          },
          "layer_20": {
            "total": 0.02043631935119629,
            "attention": {
              "total": 0.005260191917419434,
              "qkv_proj": 0.0026484799385070802,
              "rope": 0.00021532799303531646,
              "kv_append": 0.00018268799781799317,
              "attention_op": 0.0006679679751396179,
              "o_proj": 0.0014342080354690552
            },
            "ffn": 0.015112383842468262
          },
          "layer_21": {
            "total": 0.020573856353759766,
            "attention": {
              "total": 0.005256768226623535,
              "qkv_proj": 0.0026454079151153565,
              "rope": 0.00021408000588417052,
              "kv_append": 0.00018889600038528442,
              "attention_op": 0.000669152021408081,
              "o_proj": 0.0014275200366973878
            },
            "ffn": 0.015255552291870117
          },
          "layer_22": {
            "total": 0.02090332794189453,
            "attention": {
              "total": 0.005390367984771729,
              "qkv_proj": 0.0027067201137542726,
              "rope": 0.00022060799598693848,
              "kv_append": 0.00019075199961662292,
              "attention_op": 0.0006907520294189454,
              "o_proj": 0.001469696044921875
            },
            "ffn": 0.015451168060302735
          },
          "layer_23": {
            "total": 0.020903583526611327,
            "attention": {
              "total": 0.005372896194458008,
              "qkv_proj": 0.0027107839584350588,
              "rope": 0.00021331200003623963,
              "kv_append": 0.0001910720020532608,
              "attention_op": 0.000681439995765686,
              "o_proj": 0.0014633280038833618
            },
            "ffn": 0.01546787166595459
          },
          "layer_24": {
            "total": 0.020454656600952147,
            "attention": {
              "total": 0.005317247867584228,
              "qkv_proj": 0.002701920032501221,
              "rope": 0.0002143999934196472,
              "kv_append": 0.00018649600446224212,
              "attention_op": 0.0006741120219230652,
              "o_proj": 0.001430783987045288
            },
            "ffn": 0.01507472038269043
          },
          "layer_25": {
            "total": 0.02026451110839844,
            "attention": {
              "total": 0.005234240055084228,
              "qkv_proj": 0.0026353280544281006,
              "rope": 0.00021423999965190888,
              "kv_append": 0.00018592000007629393,
              "attention_op": 0.0006645119786262512,
              "o_proj": 0.0014219839572906495
            },
            "ffn": 0.014968607902526855
          },
          "layer_26": {
            "total": 0.02000214385986328,
            "attention": {
              "total": 0.005184671878814697,
              "qkv_proj": 0.0026039040088653566,
              "rope": 0.00021161599457263945,
              "kv_append": 0.00018531200289726257,
              "attention_op": 0.0006506239771842956,
              "o_proj": 0.0014084479808807373
            },
            "ffn": 0.014757120132446289
          },
          "layer_27": {
            "total": 0.02020195198059082,
            "attention": {
              "total": 0.005214943885803223,
              "qkv_proj": 0.002615488052368164,
              "rope": 0.0002120639979839325,
              "kv_append": 0.00018515199422836304,
              "attention_op": 0.000678879976272583,
              "o_proj": 0.001409824013710022
            },
            "ffn": 0.01492416000366211
          },
          "layer_28": {
            "total": 0.020387392044067382,
            "attention": {
              "total": 0.005257440090179443,
              "qkv_proj": 0.002643199920654297,
              "rope": 0.00021404799818992615,
              "kv_append": 0.00018396799266338348,
              "attention_op": 0.0006735360026359558,
              "o_proj": 0.001430848002433777
            },
            "ffn": 0.015067296028137207
          },
          "layer_29": {
            "total": 0.02012371253967285,
            "attention": {
              "total": 0.0052146239280700685,
              "qkv_proj": 0.002629983901977539,
              "rope": 0.00021040000021457672,
              "kv_append": 0.00018751999735832216,
              "attention_op": 0.0006569600105285644,
              "o_proj": 0.0014171520471572877
            },
            "ffn": 0.014848640441894531
          },
          "layer_30": {
            "total": 0.020100831985473633,
            "attention": {
              "total": 0.005200607776641846,
              "qkv_proj": 0.0026190080642700194,
              "rope": 0.0002143999934196472,
              "kv_append": 0.00018384000658988952,
              "attention_op": 0.0006561279892921448,
              "o_proj": 0.001415168046951294
            },
            "ffn": 0.014839263916015625
          },
          "layer_31": {
            "total": 0.020127487182617188,
            "attention": {
              "total": 0.005192351818084717,
              "qkv_proj": 0.002616640090942383,
              "rope": 0.0002112639993429184,
              "kv_append": 0.0001834239959716797,
              "attention_op": 0.0006572480201721191,
              "o_proj": 0.0014114559888839721
            },
            "ffn": 0.014870335578918457
          }
        }
      },
      "lm_head": 0.0449810562133789
    },
    "last_decode_op_times": {
      "input_preparation": 0.00020399999618530274,
      "kv_cache_allocation": 0.00036934399604797365,
      "flashinfer_planning": 0.00013388800621032715,
      "embedding_lookup": 2.9759999364614487e-05,
      "transformer_layers": {
        "layer_time": 0.024793663918972017,
        "attention_time": 0.015696351975202562,
        "ffn_time": 0.007686079978942871,
        "detailed_layers": {
          "layer_0": {
            "total": 0.0008025280237197876,
            "attention": {
              "total": 0.0005192319750785828,
              "qkv_proj": 0.0001377280056476593,
              "rope": 2.54720002412796e-05,
              "kv_append": 9.136000275611877e-05,
              "attention_op": 0.00011401599645614625,
              "o_proj": 5.507199838757515e-05
            },
            "ffn": 0.0002415360063314438
          },
          "layer_1": {
            "total": 0.0007854080200195312,
            "attention": {
              "total": 0.0005018879771232605,
              "qkv_proj": 0.00012070400267839432,
              "rope": 2.4639999493956565e-05,
              "kv_append": 8.748800307512284e-05,
              "attention_op": 0.00011247999966144561,
              "o_proj": 5.4207999259233475e-05
            },
            "ffn": 0.0002396479994058609
          },
          "layer_2": {
            "total": 0.0007816960215568543,
            "attention": {
              "total": 0.0004949760138988495,
              "qkv_proj": 0.00011939200013875961,
              "rope": 2.5119999423623085e-05,
              "kv_append": 8.291199803352356e-05,
              "attention_op": 0.00011324799805879592,
              "o_proj": 5.4944001138210295e-05
            },
            "ffn": 0.0002425599992275238
          },
          "layer_3": {
            "total": 0.0007853760123252869,
            "attention": {
              "total": 0.0004945279955863953,
              "qkv_proj": 0.00012044800072908401,
              "rope": 2.4800000712275504e-05,
              "kv_append": 8.43840017914772e-05,
              "attention_op": 0.00011132799834012986,
              "o_proj": 5.2960000932216646e-05
            },
            "ffn": 0.0002474559992551804
          },
          "layer_4": {
            "total": 0.0007770559787750244,
            "attention": {
              "total": 0.0004928640127182007,
              "qkv_proj": 0.00012054400146007538,
              "rope": 2.5216000154614447e-05,
              "kv_append": 8.265600353479385e-05,
              "attention_op": 0.00011151999980211257,
              "o_proj": 5.33440001308918e-05
            },
            "ffn": 0.00024031999707221986
          },
          "layer_5": {
            "total": 0.0007749760150909424,
            "attention": {
              "total": 0.0004928640127182007,
              "qkv_proj": 0.00012086399644613266,
              "rope": 2.5056000798940658e-05,
              "kv_append": 8.169600367546081e-05,
              "attention_op": 0.00011356800049543381,
              "o_proj": 5.235200002789497e-05
            },
            "ffn": 0.00023827199637889863
          },
          "layer_6": {
            "total": 0.0007753599882125854,
            "attention": {
              "total": 0.0004909760057926178,
              "qkv_proj": 0.00011952000111341476,
              "rope": 2.4480000138282777e-05,
              "kv_append": 8.271999657154083e-05,
              "attention_op": 0.00011203200370073319,
              "o_proj": 5.369599908590317e-05
            },
            "ffn": 0.00024025599658489228
          },
          "layer_7": {
            "total": 0.0007683200240135193,
            "attention": {
              "total": 0.000484607994556427,
              "qkv_proj": 0.00011683200299739837,
              "rope": 2.5056000798940658e-05,
              "kv_append": 7.881599664688111e-05,
              "attention_op": 0.00011151999980211257,
              "o_proj": 5.340800061821938e-05
            },
            "ffn": 0.00024035200476646423
          },
          "layer_8": {
            "total": 0.0007683839797973632,
            "attention": {
              "total": 0.00048480001091957093,
              "qkv_proj": 0.00011734399944543839,
              "rope": 2.44159996509552e-05,
              "kv_append": 8.04160013794899e-05,
              "attention_op": 0.00011084800213575363,
              "o_proj": 5.41439987719059e-05
            },
            "ffn": 0.00024067200720310212
          },
          "layer_9": {
            "total": 0.0007745919823646545,
            "attention": {
              "total": 0.0004912959933280945,
              "qkv_proj": 0.00012003199756145478,
              "rope": 2.4831999093294143e-05,
              "kv_append": 8.140800148248673e-05,
              "attention_op": 0.00011273600161075592,
              "o_proj": 5.318399891257286e-05
            },
            "ffn": 0.00023929600417613983
          },
          "layer_10": {
            "total": 0.0007703999876976013,
            "attention": {
              "total": 0.0004862399995326996,
              "qkv_proj": 0.00011664000153541566,
              "rope": 2.4703999981284142e-05,
              "kv_append": 8.1216000020504e-05,
              "attention_op": 0.00011100800335407257,
              "o_proj": 5.481600016355515e-05
            },
            "ffn": 0.0002404160052537918
          },
          "layer_11": {
            "total": 0.0007745599746704101,
            "attention": {
              "total": 0.000489791989326477,
              "qkv_proj": 0.0001188800036907196,
              "rope": 2.425600029528141e-05,
              "kv_append": 8.048000186681748e-05,
              "attention_op": 0.00011321599781513213,
              "o_proj": 5.430399999022484e-05
            },
            "ffn": 0.00024076800048351287
          },
          "layer_12": {
            "total": 0.0007709760069847107,
            "attention": {
              "total": 0.0004884159862995148,
              "qkv_proj": 0.00011843200027942658,
              "rope": 2.4927999824285508e-05,
              "kv_append": 8.076799660921096e-05,
              "attention_op": 0.00011296000331640244,
              "o_proj": 5.25440014898777e-05
            },
            "ffn": 0.00023916800320148468
          },
          "layer_13": {
            "total": 0.0007724800109863281,
            "attention": {
              "total": 0.0004904319941997528,
              "qkv_proj": 0.00011961600184440613,
              "rope": 2.4127999320626257e-05,
              "kv_append": 8.156800270080566e-05,
              "attention_op": 0.00011100800335407257,
              "o_proj": 5.404800176620483e-05
            },
            "ffn": 0.00023827199637889863
          },
          "layer_14": {
            "total": 0.0007744320034980774,
            "attention": {
              "total": 0.0004890240132808685,
              "qkv_proj": 0.0001207680031657219,
              "rope": 2.438399940729141e-05,
              "kv_append": 8.124800026416779e-05,
              "attention_op": 0.00011110399663448334,
              "o_proj": 5.363199859857559e-05
            },
            "ffn": 0.00024220800399780274
          },
          "layer_15": {
            "total": 0.0007690879702568055,
            "attention": {
              "total": 0.0004860799908638001,
              "qkv_proj": 0.00011705599725246429,
              "rope": 2.502400055527687e-05,
              "kv_append": 7.983999699354171e-05,
              "attention_op": 0.00011267200112342834,
              "o_proj": 5.286400020122528e-05
            },
            "ffn": 0.00023878400027751921
          },
          "layer_16": {
            "total": 0.0007700799703598023,
            "attention": {
              "total": 0.00048716801404953005,
              "qkv_proj": 0.00011724799871444702,
              "rope": 2.454400062561035e-05,
              "kv_append": 8.083199709653854e-05,
              "attention_op": 0.00011110399663448334,
              "o_proj": 5.385600030422211e-05
            },
            "ffn": 0.0002393919974565506
          },
          "layer_17": {
            "total": 0.0007751680016517639,
            "attention": {
              "total": 0.0004911360144615174,
              "qkv_proj": 0.00011846400052309036,
              "rope": 2.534399926662445e-05,
              "kv_append": 8.153600245714187e-05,
              "attention_op": 0.00011270400136709213,
              "o_proj": 5.369599908590317e-05
            },
            "ffn": 0.00023996800184249877
          },
          "layer_18": {
            "total": 0.0007750399708747864,
            "attention": {
              "total": 0.0004886080026626587,
              "qkv_proj": 0.0001181119978427887,
              "rope": 2.5087999179959297e-05,
              "kv_append": 8.233600109815597e-05,
              "attention_op": 0.000111455999314785,
              "o_proj": 5.356800183653831e-05
            },
            "ffn": 0.00024198399484157563
          },
          "layer_19": {
            "total": 0.0007767999768257141,
            "attention": {
              "total": 0.0004926080107688904,
              "qkv_proj": 0.00012150400131940842,
              "rope": 2.4639999493956565e-05,
              "kv_append": 8.1216000020504e-05,
              "attention_op": 0.00011203200370073319,
              "o_proj": 5.2992001175880435e-05
            },
            "ffn": 0.00024025599658489228
          },
          "layer_20": {
            "total": 0.0007675520181655884,
            "attention": {
              "total": 0.00048480001091957093,
              "qkv_proj": 0.00011776000261306762,
              "rope": 2.438399940729141e-05,
              "kv_append": 7.926400005817413e-05,
              "attention_op": 0.00011174400150775909,
              "o_proj": 5.3279999643564224e-05
            },
            "ffn": 0.00023945599794387819
          },
          "layer_21": {
            "total": 0.0007703679800033569,
            "attention": {
              "total": 0.00048684799671173094,
              "qkv_proj": 0.00011961600184440613,
              "rope": 2.425600029528141e-05,
              "kv_append": 7.983999699354171e-05,
              "attention_op": 0.00011126399785280228,
              "o_proj": 5.311999842524528e-05
            },
            "ffn": 0.00023919999599456788
          },
          "layer_22": {
            "total": 0.0007733439803123474,
            "attention": {
              "total": 0.0004886080026626587,
              "qkv_proj": 0.00011977600306272507,
              "rope": 2.4095999076962472e-05,
              "kv_append": 8.01599994301796e-05,
              "attention_op": 0.00011151999980211257,
              "o_proj": 5.3920000791549686e-05
            },
            "ffn": 0.0002399359941482544
          },
          "layer_23": {
            "total": 0.0007718080282211304,
            "attention": {
              "total": 0.00048819199204444883,
              "qkv_proj": 0.00011846400052309036,
              "rope": 2.4639999493956565e-05,
              "kv_append": 7.865600287914277e-05,
              "attention_op": 0.00011299200356006623,
              "o_proj": 5.491200089454651e-05
            },
            "ffn": 0.00023926399648189546
          },
          "layer_24": {
            "total": 0.0007739840149879456,
            "attention": {
              "total": 0.000491104006767273,
              "qkv_proj": 0.000121568001806736,
              "rope": 2.4831999093294143e-05,
              "kv_append": 8.156800270080566e-05,
              "attention_op": 0.00011055999994277953,
              "o_proj": 5.321599915623665e-05
            },
            "ffn": 0.00023919999599456788
          },
          "layer_25": {
            "total": 0.0007705600261688233,
            "attention": {
              "total": 0.00048742398619651796,
              "qkv_proj": 0.00011900799721479416,
              "rope": 2.4032000452280045e-05,
              "kv_append": 7.903999835252761e-05,
              "attention_op": 0.00011241599917411804,
              "o_proj": 5.3727999329566956e-05
            },
            "ffn": 0.0002391359955072403
          },
          "layer_26": {
            "total": 0.0007750719785690307,
            "attention": {
              "total": 0.0004927360117435455,
              "qkv_proj": 0.00012025599926710128,
              "rope": 2.4927999824285508e-05,
              "kv_append": 8.220800012350083e-05,
              "attention_op": 0.00011296000331640244,
              "o_proj": 5.395200103521347e-05
            },
            "ffn": 0.00023887999355793
          },
          "layer_27": {
            "total": 0.0007680000066757202,
            "attention": {
              "total": 0.00048473599553108213,
              "qkv_proj": 0.000118367999792099,
              "rope": 2.4191999807953834e-05,
              "kv_append": 7.974400371313095e-05,
              "attention_op": 0.0001117120012640953,
              "o_proj": 5.283199995756149e-05
            },
            "ffn": 0.00023942400515079498
          },
          "layer_28": {
            "total": 0.0007834879755973816,
            "attention": {
              "total": 0.0004872959852218628,
              "qkv_proj": 0.00011779200285673141,
              "rope": 2.4512000381946565e-05,
              "kv_append": 8.124800026416779e-05,
              "attention_op": 0.00011148799955844879,
              "o_proj": 5.2960000932216646e-05
            },
            "ffn": 0.0002407039999961853
          },
          "layer_29": {
            "total": 0.0007763199806213379,
            "attention": {
              "total": 0.0004943999946117402,
              "qkv_proj": 0.00012310399860143663,
              "rope": 2.5056000798940658e-05,
              "kv_append": 8.01599994301796e-05,
              "attention_op": 0.00011244799941778183,
              "o_proj": 5.38880005478859e-05
            },
            "ffn": 0.00023846399784088136
          },
          "layer_30": {
            "total": 0.0007706239819526672,
            "attention": {
              "total": 0.0004863680005073547,
              "qkv_proj": 0.00011840000003576279,
              "rope": 2.4800000712275504e-05,
              "kv_append": 8.076799660921096e-05,
              "attention_op": 0.00011097600311040878,
              "o_proj": 5.3536001592874524e-05
            },
            "ffn": 0.00024108800292015075
          },
          "layer_31": {
            "total": 0.0007698240280151368,
            "attention": {
              "total": 0.000486303985118866,
              "qkv_proj": 0.00011913599818944931,
              "rope": 2.4831999093294143e-05,
              "kv_append": 7.903999835252761e-05,
              "attention_op": 0.00011209599673748017,
              "o_proj": 5.263999849557876e-05
            },
            "ffn": 0.00023974399268627167
          }
        }
      },
      "lm_head": 0.0004875519871711731
    },
    "longest_op": "lm_head",
    "longest_op_time": 0.0004875519871711731
  },
  {
    "decode_length": 256,
    "log_decode_length": 8.0,
    "prefill_time": 0.7433276176452637,
    "decode_time": 7.025495767593384,
    "total_time": 7.7688233852386475,
    "prefill_op_times": {
      "input_preparation": 0.0002264000028371811,
      "kv_cache_allocation": 0.0006696000099182129,
      "flashinfer_planning": 0.00023996800184249877,
      "embedding_lookup": 0.0004312959909439087,
      "transformer_layers": {
        "layer_time": 0.652174970626831,
        "attention_time": 0.16797183799743656,
        "ffn_time": 0.482168927192688,
        "detailed_layers": {
          "layer_0": {
            "total": 0.01936367988586426,
            "attention": {
              "total": 0.005085631847381592,
              "qkv_proj": 0.0025571839809417725,
              "rope": 0.00021459199488162994,
              "kv_append": 0.00023004800081253052,
              "attention_op": 0.0005936639904975891,
              "o_proj": 0.0013785279989242554
            },
            "ffn": 0.014217823982238769
          },
          "layer_1": {
            "total": 0.019355840682983398,
            "attention": {
              "total": 0.005024703979492187,
              "qkv_proj": 0.0025386240482330323,
              "rope": 0.00021011200547218324,
              "kv_append": 0.00018512000143527984,
              "attention_op": 0.0005906559824943543,
              "o_proj": 0.001384768009185791
            },
            "ffn": 0.01426972770690918
          },
          "layer_2": {
            "total": 0.020190080642700194,
            "attention": {
              "total": 0.005115359783172607,
              "qkv_proj": 0.0025859200954437256,
              "rope": 0.00021135999262332917,
              "kv_append": 0.00018617600202560424,
              "attention_op": 0.0006244800090789795,
              "o_proj": 0.001393183946609497
            },
            "ffn": 0.015006272315979004
          },
          "layer_3": {
            "total": 0.020303871154785155,
            "attention": {
              "total": 0.005233119964599609,
              "qkv_proj": 0.0026329920291900634,
              "rope": 0.00021318399906158447,
              "kv_append": 0.00018515199422836304,
              "attention_op": 0.0006636800169944763,
              "o_proj": 0.0014213759899139404
            },
            "ffn": 0.015006336212158203
          },
          "layer_4": {
            "total": 0.020267648696899412,
            "attention": {
              "total": 0.005233727931976319,
              "qkv_proj": 0.0026316800117492677,
              "rope": 0.00021219199895858765,
              "kv_append": 0.00019014400243759155,
              "attention_op": 0.0006614720225334167,
              "o_proj": 0.0014233920574188233
            },
            "ffn": 0.01497107219696045
          },
          "layer_5": {
            "total": 0.02047488021850586,
            "attention": {
              "total": 0.005214047908782959,
              "qkv_proj": 0.002621407985687256,
              "rope": 0.0002135999947786331,
              "kv_append": 0.00018700799345970154,
              "attention_op": 0.0006607360243797302,
              "o_proj": 0.001418239951133728
            },
            "ffn": 0.015199359893798827
          },
          "layer_6": {
            "total": 0.02058083152770996,
            "attention": {
              "total": 0.005287968158721924,
              "qkv_proj": 0.0026655359268188475,
              "rope": 0.00021241599321365355,
              "kv_append": 0.00018479999899864198,
              "attention_op": 0.00067603200674057,
              "o_proj": 0.0014366719722747803
            },
            "ffn": 0.01522697639465332
          },
          "layer_7": {
            "total": 0.02058451271057129,
            "attention": {
              "total": 0.005294271945953369,
              "qkv_proj": 0.0026605761051177977,
              "rope": 0.0002149759978055954,
              "kv_append": 0.00018918399512767793,
              "attention_op": 0.000676800012588501,
              "o_proj": 0.0014384000301361085
            },
            "ffn": 0.015226304054260254
          },
          "layer_8": {
            "total": 0.020586015701293946,
            "attention": {
              "total": 0.005291776180267334,
              "qkv_proj": 0.00266211199760437,
              "rope": 0.00021484799683094025,
              "kv_append": 0.00019062399864196777,
              "attention_op": 0.000672864019870758,
              "o_proj": 0.0014359359741210938
            },
            "ffn": 0.015215840339660645
          },
          "layer_9": {
            "total": 0.020587743759155272,
            "attention": {
              "total": 0.005318336009979248,
              "qkv_proj": 0.002669856071472168,
              "rope": 0.00021753600239753722,
              "kv_append": 0.00019686399400234222,
              "attention_op": 0.000679647982120514,
              "o_proj": 0.001438688039779663
            },
            "ffn": 0.015208160400390625
          },
          "layer_10": {
            "total": 0.02056060791015625,
            "attention": {
              "total": 0.005291711807250976,
              "qkv_proj": 0.0026698238849639892,
              "rope": 0.00021302400529384614,
              "kv_append": 0.0001825920045375824,
              "attention_op": 0.0006718720197677612,
              "o_proj": 0.0014375679492950439
            },
            "ffn": 0.015204319953918457
          },
          "layer_11": {
            "total": 0.02074025535583496,
            "attention": {
              "total": 0.005336959838867187,
              "qkv_proj": 0.002689471960067749,
              "rope": 0.00021436800062656403,
              "kv_append": 0.00018764799833297728,
              "attention_op": 0.0006793919801712036,
              "o_proj": 0.0014512959718704223
            },
            "ffn": 0.015338687896728516
          },
          "layer_12": {
            "total": 0.02075507164001465,
            "attention": {
              "total": 0.005349055767059326,
              "qkv_proj": 0.00268176007270813,
              "rope": 0.00021590399742126465,
              "kv_append": 0.00020422400534152985,
              "attention_op": 0.0006778879761695862,
              "o_proj": 0.001453984022140503
            },
            "ffn": 0.015343520164489746
          },
          "layer_13": {
            "total": 0.020716768264770508,
            "attention": {
              "total": 0.005329311847686768,
              "qkv_proj": 0.002676640033721924,
              "rope": 0.0002160319983959198,
              "kv_append": 0.00019196799397468568,
              "attention_op": 0.0006807360053062439,
              "o_proj": 0.0014488639831542968
            },
            "ffn": 0.015325471878051758
          },
          "layer_14": {
            "total": 0.020736223220825196,
            "attention": {
              "total": 0.005332672119140625,
              "qkv_proj": 0.0026872320175170897,
              "rope": 0.00021561600267887117,
              "kv_append": 0.00018419200181961058,
              "attention_op": 0.000679199993610382,
              "o_proj": 0.0014506560564041138
            },
            "ffn": 0.01533795166015625
          },
          "layer_15": {
            "total": 0.020694847106933593,
            "attention": {
              "total": 0.005326560020446777,
              "qkv_proj": 0.0026790080070495607,
              "rope": 0.00021430400013923645,
              "kv_append": 0.000191103994846344,
              "attention_op": 0.0006809279918670654,
              "o_proj": 0.0014470080137252807
            },
            "ffn": 0.0153056001663208
          },
          "layer_16": {
            "total": 0.020533119201660156,
            "attention": {
              "total": 0.005286687850952148,
              "qkv_proj": 0.002662719964981079,
              "rope": 0.00021408000588417052,
              "kv_append": 0.00018624000251293182,
              "attention_op": 0.0006705920100212097,
              "o_proj": 0.0014380799531936645
            },
            "ffn": 0.015179743766784668
          },
          "layer_17": {
            "total": 0.02046396827697754,
            "attention": {
              "total": 0.005272192001342773,
              "qkv_proj": 0.0026488959789276122,
              "rope": 0.00021580800414085387,
              "kv_append": 0.00018707199394702912,
              "attention_op": 0.0006699519753456116,
              "o_proj": 0.0014336960315704346
            },
            "ffn": 0.01513167953491211
          },
          "layer_18": {
            "total": 0.02057088088989258,
            "attention": {
              "total": 0.0052845759391784665,
              "qkv_proj": 0.0026619839668273926,
              "rope": 0.00021305599808692932,
              "kv_append": 0.00019120000302791596,
              "attention_op": 0.0006709120273590088,
              "o_proj": 0.0014335999488830566
            },
            "ffn": 0.01522332763671875
          },
          "layer_19": {
            "total": 0.020528160095214843,
            "attention": {
              "total": 0.005290080070495606,
              "qkv_proj": 0.0026628479957580566,
              "rope": 0.00021484799683094025,
              "kv_append": 0.00018886399269104004,
              "attention_op": 0.0006719040274620056,
              "o_proj": 0.0014349119663238526
            },
            "ffn": 0.015176735877990722
          },
          "layer_20": {
            "total": 0.02041472053527832,
            "attention": {
              "total": 0.005257919788360595,
              "qkv_proj": 0.002647455930709839,
              "rope": 0.00021423999965190888,
              "kv_append": 0.00018544000387191772,
              "attention_op": 0.0006672639846801758,
              "o_proj": 0.0014260799884796142
            },
            "ffn": 0.015096447944641113
          },
          "layer_21": {
            "total": 0.020245855331420898,
            "attention": {
              "total": 0.005223519802093506,
              "qkv_proj": 0.002629120111465454,
              "rope": 0.0002147520035505295,
              "kv_append": 0.00018476800620555878,
              "attention_op": 0.000662559986114502,
              "o_proj": 0.0014176959991455077
            },
            "ffn": 0.014961024284362794
          },
          "layer_22": {
            "total": 0.020249055862426757,
            "attention": {
              "total": 0.00521673583984375,
              "qkv_proj": 0.002629568099975586,
              "rope": 0.00021344000101089478,
              "kv_append": 0.0001839040070772171,
              "attention_op": 0.000660319983959198,
              "o_proj": 0.0014159040451049805
            },
            "ffn": 0.01496992015838623
          },
          "layer_23": {
            "total": 0.020243423461914063,
            "attention": {
              "total": 0.005230847835540771,
              "qkv_proj": 0.0026328639984130858,
              "rope": 0.0002133760005235672,
              "kv_append": 0.00018729600310325622,
              "attention_op": 0.0006633279919624329,
              "o_proj": 0.001418079972267151
            },
            "ffn": 0.014951168060302734
          },
          "layer_24": {
            "total": 0.02023583984375,
            "attention": {
              "total": 0.005218016147613525,
              "qkv_proj": 0.00262774395942688,
              "rope": 0.0002136960029602051,
              "kv_append": 0.0001879359930753708,
              "attention_op": 0.0006596159934997559,
              "o_proj": 0.0014151359796524049
            },
            "ffn": 0.014955583572387696
          },
          "layer_25": {
            "total": 0.020283807754516603,
            "attention": {
              "total": 0.0052284798622131345,
              "qkv_proj": 0.0026285760402679445,
              "rope": 0.00021420800685882567,
              "kv_append": 0.0001931840032339096,
              "attention_op": 0.0006643840074539184,
              "o_proj": 0.0014147520065307616
            },
            "ffn": 0.0149933443069458
          },
          "layer_26": {
            "total": 0.020323936462402343,
            "attention": {
              "total": 0.005229311943054199,
              "qkv_proj": 0.0026359360218048094,
              "rope": 0.00021161599457263945,
              "kv_append": 0.00018585599958896636,
              "attention_op": 0.0006638079881668091,
              "o_proj": 0.0014180159568786621
            },
            "ffn": 0.015030559539794921
          },
          "layer_27": {
            "total": 0.020333343505859375,
            "attention": {
              "total": 0.005235551834106445,
              "qkv_proj": 0.002636159896850586,
              "rope": 0.0002128639966249466,
              "kv_append": 0.00018467199802398683,
              "attention_op": 0.0006650239825248718,
              "o_proj": 0.001422752022743225
            },
            "ffn": 0.015033247947692872
          },
          "layer_28": {
            "total": 0.020205759048461915,
            "attention": {
              "total": 0.005227456092834473,
              "qkv_proj": 0.0026327359676361086,
              "rope": 0.00021382400393486024,
              "kv_append": 0.00018323199450969696,
              "attention_op": 0.0006638079881668091,
              "o_proj": 0.0014218560457229614
            },
            "ffn": 0.014914079666137696
          },
          "layer_29": {
            "total": 0.020443487167358398,
            "attention": {
              "total": 0.0052540478706359865,
              "qkv_proj": 0.0026264638900756836,
              "rope": 0.00021449600160121919,
              "kv_append": 0.00018646399676799775,
              "attention_op": 0.0006808000206947327,
              "o_proj": 0.0014338879585266114
            },
            "ffn": 0.015126463890075683
          },
          "layer_30": {
            "total": 0.02031782341003418,
            "attention": {
              "total": 0.005222303867340088,
              "qkv_proj": 0.002633888006210327,
              "rope": 0.000211776003241539,
              "kv_append": 0.00018457600474357605,
              "attention_op": 0.0006612160205841064,
              "o_proj": 0.001418944001197815
            },
            "ffn": 0.015032032012939452
          },
          "layer_31": {
            "total": 0.02028291130065918,
            "attention": {
              "total": 0.0052288961410522465,
              "qkv_proj": 0.00263372802734375,
              "rope": 0.000213919997215271,
              "kv_append": 0.00018400000035762788,
              "attention_op": 0.0006629440188407898,
              "o_proj": 0.001420896053314209
            },
            "ffn": 0.014990143775939942
          }
        }
      },
      "lm_head": 0.04444604873657226
    },
    "last_decode_op_times": {
      "input_preparation": 0.0002080319970846176,
      "kv_cache_allocation": 0.00040928000211715697,
      "flashinfer_planning": 0.0001321599930524826,
      "embedding_lookup": 3.033600002527237e-05,
      "transformer_layers": {
        "layer_time": 0.0255741121172905,
        "attention_time": 0.016487136006355284,
        "ffn_time": 0.007684319987893105,
        "detailed_layers": {
          "layer_0": {
            "total": 0.000840224027633667,
            "attention": {
              "total": 0.0005525760054588318,
              "qkv_proj": 0.0001409599930047989,
              "rope": 2.6016000658273698e-05,
              "kv_append": 9.718400239944459e-05,
              "attention_op": 0.00013574400544166565,
              "o_proj": 5.593600124120712e-05
            },
            "ffn": 0.000244159996509552
          },
          "layer_1": {
            "total": 0.0008129600286483765,
            "attention": {
              "total": 0.0005276479721069336,
              "qkv_proj": 0.00012185599654912949,
              "rope": 2.5536000728607178e-05,
              "kv_append": 8.793599903583526e-05,
              "attention_op": 0.0001358720064163208,
              "o_proj": 5.5711999535560605e-05
            },
            "ffn": 0.0002412479966878891
          },
          "layer_2": {
            "total": 0.0008089600205421448,
            "attention": {
              "total": 0.0005246080160140991,
              "qkv_proj": 0.00012399999797344207,
              "rope": 2.4512000381946565e-05,
              "kv_append": 8.585599809885026e-05,
              "attention_op": 0.00013548800349235535,
              "o_proj": 5.523199960589409e-05
            },
            "ffn": 0.00024054400622844696
          },
          "layer_3": {
            "total": 0.0008085119724273682,
            "attention": {
              "total": 0.000522816002368927,
              "qkv_proj": 0.00012515200674533843,
              "rope": 2.5536000728607178e-05,
              "kv_append": 8.28159973025322e-05,
              "attention_op": 0.0001356479972600937,
              "o_proj": 5.427199974656105e-05
            },
            "ffn": 0.00024108800292015075
          },
          "layer_4": {
            "total": 0.0008015360236167908,
            "attention": {
              "total": 0.0005167040228843689,
              "qkv_proj": 0.00012054400146007538,
              "rope": 2.5056000798940658e-05,
              "kv_append": 8.425600081682205e-05,
              "attention_op": 0.00013372799754142762,
              "o_proj": 5.3440000861883166e-05
            },
            "ffn": 0.00024108800292015075
          },
          "layer_5": {
            "total": 0.0007968320250511169,
            "attention": {
              "total": 0.0005138239860534668,
              "qkv_proj": 0.00011900799721479416,
              "rope": 2.4768000468611716e-05,
              "kv_append": 8.310399949550629e-05,
              "attention_op": 0.00013494400680065155,
              "o_proj": 5.302400141954422e-05
            },
            "ffn": 0.00024022400379180908
          },
          "layer_6": {
            "total": 0.0007929279804229736,
            "attention": {
              "total": 0.000509663999080658,
              "qkv_proj": 0.00011791999638080597,
              "rope": 2.4671999737620354e-05,
              "kv_append": 8.160000294446945e-05,
              "attention_op": 0.00013439999520778657,
              "o_proj": 5.283199995756149e-05
            },
            "ffn": 0.00023951999843120576
          },
          "layer_7": {
            "total": 0.000798080027103424,
            "attention": {
              "total": 0.0005141440033912659,
              "qkv_proj": 0.00012009599804878235,
              "rope": 2.499200031161308e-05,
              "kv_append": 8.28159973025322e-05,
              "attention_op": 0.00013462400436401367,
              "o_proj": 5.3440000861883166e-05
            },
            "ffn": 0.00024025599658489228
          },
          "layer_8": {
            "total": 0.0008023040294647217,
            "attention": {
              "total": 0.000519327998161316,
              "qkv_proj": 0.00012195199728012086,
              "rope": 2.5407999753952028e-05,
              "kv_append": 8.463999629020691e-05,
              "attention_op": 0.00013449600338935852,
              "o_proj": 5.267199873924255e-05
            },
            "ffn": 0.00023894399404525757
          },
          "layer_9": {
            "total": 0.0007944639921188355,
            "attention": {
              "total": 0.0005104320049285889,
              "qkv_proj": 0.00011856000125408172,
              "rope": 2.5280000641942024e-05,
              "kv_append": 8.150400221347808e-05,
              "attention_op": 0.00013484799861907958,
              "o_proj": 5.321599915623665e-05
            },
            "ffn": 0.00023984000086784362
          },
          "layer_10": {
            "total": 0.0007977280020713807,
            "attention": {
              "total": 0.0005151039958000183,
              "qkv_proj": 0.0001181119978427887,
              "rope": 2.4671999737620354e-05,
              "kv_append": 8.364800363779068e-05,
              "attention_op": 0.0001350400000810623,
              "o_proj": 5.311999842524528e-05
            },
            "ffn": 0.0002380799949169159
          },
          "layer_11": {
            "total": 0.0007989439964294434,
            "attention": {
              "total": 0.0005155839920043945,
              "qkv_proj": 0.0001189119964838028,
              "rope": 2.473600022494793e-05,
              "kv_append": 8.393599838018418e-05,
              "attention_op": 0.00013497599959373473,
              "o_proj": 5.3536001592874524e-05
            },
            "ffn": 0.0002396160066127777
          },
          "layer_12": {
            "total": 0.0008022080063819885,
            "attention": {
              "total": 0.000511680006980896,
              "qkv_proj": 0.000118367999792099,
              "rope": 2.473600022494793e-05,
              "kv_append": 8.28159973025322e-05,
              "attention_op": 0.0001340160071849823,
              "o_proj": 5.315199866890907e-05
            },
            "ffn": 0.000246751993894577
          },
          "layer_13": {
            "total": 0.0007971199750900268,
            "attention": {
              "total": 0.0005125439763069153,
              "qkv_proj": 0.0001196800023317337,
              "rope": 2.5087999179959297e-05,
              "kv_append": 8.064000308513641e-05,
              "attention_op": 0.00013465599715709687,
              "o_proj": 5.3504001349210736e-05
            },
            "ffn": 0.00024038399755954744
          },
          "layer_14": {
            "total": 0.0007967360019683838,
            "attention": {
              "total": 0.0005139840245246887,
              "qkv_proj": 0.0001178240031003952,
              "rope": 2.5087999179959297e-05,
              "kv_append": 8.259200304746628e-05,
              "attention_op": 0.00013462400436401367,
              "o_proj": 5.35999983549118e-05
            },
            "ffn": 0.0002375359982252121
          },
          "layer_15": {
            "total": 0.0007995200157165527,
            "attention": {
              "total": 0.0005150719881057739,
              "qkv_proj": 0.00011939200013875961,
              "rope": 2.5183999910950662e-05,
              "kv_append": 8.22720006108284e-05,
              "attention_op": 0.00013523200154304504,
              "o_proj": 5.481600016355515e-05
            },
            "ffn": 0.00024108800292015075
          },
          "layer_16": {
            "total": 0.0007975680232048034,
            "attention": {
              "total": 0.0005122240185737609,
              "qkv_proj": 0.00011753600090742112,
              "rope": 2.4831999093294143e-05,
              "kv_append": 8.150400221347808e-05,
              "attention_op": 0.00013347199559211732,
              "o_proj": 5.455999821424484e-05
            },
            "ffn": 0.00024086399376392365
          },
          "layer_17": {
            "total": 0.0008045759797096252,
            "attention": {
              "total": 0.0005203840136528015,
              "qkv_proj": 0.00011846400052309036,
              "rope": 2.502400055527687e-05,
              "kv_append": 8.118399977684021e-05,
              "attention_op": 0.00013571199774742125,
              "o_proj": 5.292800068855286e-05
            },
            "ffn": 0.00024079999327659607
          },
          "layer_18": {
            "total": 0.0007950400114059449,
            "attention": {
              "total": 0.0005101119875907898,
              "qkv_proj": 0.00011750400066375733,
              "rope": 2.502400055527687e-05,
              "kv_append": 8.131200075149537e-05,
              "attention_op": 0.00013436800241470336,
              "o_proj": 5.286400020122528e-05
            },
            "ffn": 0.00024054400622844696
          },
          "layer_19": {
            "total": 0.0007951359748840332,
            "attention": {
              "total": 0.0005129920244216919,
              "qkv_proj": 0.00011903999745845795,
              "rope": 2.489599958062172e-05,
              "kv_append": 8.297599852085114e-05,
              "attention_op": 0.00013359999656677247,
              "o_proj": 5.455999821424484e-05
            },
            "ffn": 0.0002391040027141571
          },
          "layer_20": {
            "total": 0.0007947199940681458,
            "attention": {
              "total": 0.0005107839703559875,
              "qkv_proj": 0.00011750400066375733,
              "rope": 2.4831999093294143e-05,
              "kv_append": 8.297599852085114e-05,
              "attention_op": 0.00013439999520778657,
              "o_proj": 5.2480001002550127e-05
            },
            "ffn": 0.00023945599794387819
          },
          "layer_21": {
            "total": 0.0007884799838066101,
            "attention": {
              "total": 0.0005077760219573974,
              "qkv_proj": 0.0001181119978427887,
              "rope": 2.4703999981284142e-05,
              "kv_append": 8.115199953317642e-05,
              "attention_op": 0.00013305599987506865,
              "o_proj": 5.3440000861883166e-05
            },
            "ffn": 0.00023824000358581542
          },
          "layer_22": {
            "total": 0.0008000000119209289,
            "attention": {
              "total": 0.0005166400074958802,
              "qkv_proj": 0.00011932799965143204,
              "rope": 2.489599958062172e-05,
              "kv_append": 8.06720033288002e-05,
              "attention_op": 0.00013417600095272063,
              "o_proj": 5.478399991989136e-05
            },
            "ffn": 0.00023923200368881225
          },
          "layer_23": {
            "total": 0.0008005440235137939,
            "attention": {
              "total": 0.0005176960229873657,
              "qkv_proj": 0.00011961600184440613,
              "rope": 2.4447999894618988e-05,
              "kv_append": 8.326400071382522e-05,
              "attention_op": 0.00013548800349235535,
              "o_proj": 5.507199838757515e-05
            },
            "ffn": 0.00023974399268627167
          },
          "layer_24": {
            "total": 0.0007890239953994751,
            "attention": {
              "total": 0.000506335973739624,
              "qkv_proj": 0.00011760000139474868,
              "rope": 2.473600022494793e-05,
              "kv_append": 7.952000200748444e-05,
              "attention_op": 0.0001329600065946579,
              "o_proj": 5.340800061821938e-05
            },
            "ffn": 0.0002388480007648468
          },
          "layer_25": {
            "total": 0.000793824017047882,
            "attention": {
              "total": 0.0005105599761009216,
              "qkv_proj": 0.00011932799965143204,
              "rope": 2.5056000798940658e-05,
              "kv_append": 8.038400113582611e-05,
              "attention_op": 0.00013500800728797913,
              "o_proj": 5.283199995756149e-05
            },
            "ffn": 0.00024006399512290955
          },
          "layer_26": {
            "total": 0.0007943999767303467,
            "attention": {
              "total": 0.0005114240050315857,
              "qkv_proj": 0.00011878400295972824,
              "rope": 2.486399933695793e-05,
              "kv_append": 8.22720006108284e-05,
              "attention_op": 0.00013267199695110322,
              "o_proj": 5.2512001246213915e-05
            },
            "ffn": 0.00023788799345493317
          },
          "layer_27": {
            "total": 0.0007935360074043274,
            "attention": {
              "total": 0.0005089920163154602,
              "qkv_proj": 0.00011750400066375733,
              "rope": 2.454400062561035e-05,
              "kv_append": 8.035200089216233e-05,
              "attention_op": 0.00013337600231170654,
              "o_proj": 5.507199838757515e-05
            },
            "ffn": 0.00024076800048351287
          },
          "layer_28": {
            "total": 0.0007939839959144592,
            "attention": {
              "total": 0.0005111039876937866,
              "qkv_proj": 0.00011750400066375733,
              "rope": 2.627200074493885e-05,
              "kv_append": 8.336000144481659e-05,
              "attention_op": 0.00013305599987506865,
              "o_proj": 5.2960000932216646e-05
            },
            "ffn": 0.00023932799696922303
          },
          "layer_29": {
            "total": 0.0007982720136642456,
            "attention": {
              "total": 0.0005153599977493286,
              "qkv_proj": 0.00012073600292205811,
              "rope": 2.5056000798940658e-05,
              "kv_append": 8.14400017261505e-05,
              "attention_op": 0.0001356479972600937,
              "o_proj": 5.382400006055832e-05
            },
            "ffn": 0.0002393600046634674
          },
          "layer_30": {
            "total": 0.0007906879782676697,
            "attention": {
              "total": 0.0005081279873847961,
              "qkv_proj": 0.00011776000261306762,
              "rope": 2.473600022494793e-05,
              "kv_append": 7.958400249481202e-05,
              "attention_op": 0.00013427199423313141,
              "o_proj": 5.321599915623665e-05
            },
            "ffn": 0.0002391040027141571
          },
          "layer_31": {
            "total": 0.0007952640056610108,
            "attention": {
              "total": 0.0005109120011329651,
              "qkv_proj": 0.00011872000247240066,
              "rope": 2.4671999737620354e-05,
              "kv_append": 8.051200211048127e-05,
              "attention_op": 0.00013519999384880067,
              "o_proj": 5.369599908590317e-05
            },
            "ffn": 0.00024060800671577454
          }
        }
      },
      "lm_head": 0.00048665601015090943
    },
    "longest_op": "lm_head",
    "longest_op_time": 0.00048665601015090943
  },
  {
    "decode_length": 512,
    "log_decode_length": 9.0,
    "prefill_time": 0.744020938873291,
    "decode_time": 14.434998273849487,
    "total_time": 15.179019212722778,
    "prefill_op_times": {
      "input_preparation": 0.00022451199591159822,
      "kv_cache_allocation": 0.0006636800169944763,
      "flashinfer_planning": 0.00028243198990821836,
      "embedding_lookup": 0.00042934399843215943,
      "transformer_layers": {
        "layer_time": 0.6518403816223146,
        "attention_time": 0.16813740825653073,
        "ffn_time": 0.48162988853454575,
        "detailed_layers": {
          "layer_0": {
            "total": 0.019379615783691406,
            "attention": {
              "total": 0.005091104030609131,
              "qkv_proj": 0.0025570878982543945,
              "rope": 0.00021427200734615325,
              "kv_append": 0.0002170879989862442,
              "attention_op": 0.0006107839941978454,
              "o_proj": 0.0013812799453735351
            },
            "ffn": 0.01423100757598877
          },
          "layer_1": {
            "total": 0.01937548828125,
            "attention": {
              "total": 0.005053952217102051,
              "qkv_proj": 0.002553119897842407,
              "rope": 0.00021167999505996703,
              "kv_append": 0.00019631999731063843,
              "attention_op": 0.0005903360247611999,
              "o_proj": 0.001385856032371521
            },
            "ffn": 0.014258048057556153
          },
          "layer_2": {
            "total": 0.019834720611572265,
            "attention": {
              "total": 0.0051435518264770505,
              "qkv_proj": 0.00259168004989624,
              "rope": 0.0002131199985742569,
              "kv_append": 0.00018569600582122803,
              "attention_op": 0.0006365439891815185,
              "o_proj": 0.001403615951538086
            },
            "ffn": 0.014629183769226074
          },
          "layer_3": {
            "total": 0.01985296058654785,
            "attention": {
              "total": 0.00515231990814209,
              "qkv_proj": 0.002593440055847168,
              "rope": 0.0002115200012922287,
              "kv_append": 0.00018409599363803863,
              "attention_op": 0.0006422079801559448,
              "o_proj": 0.0014091520309448243
            },
            "ffn": 0.014635519981384277
          },
          "layer_4": {
            "total": 0.020156576156616212,
            "attention": {
              "total": 0.005149151802062988,
              "qkv_proj": 0.0025906879901885986,
              "rope": 0.00021372799575328826,
              "kv_append": 0.00018265600502490997,
              "attention_op": 0.0006410880088806153,
              "o_proj": 0.0014085439443588257
            },
            "ffn": 0.014945376396179199
          },
          "layer_5": {
            "total": 0.02033465576171875,
            "attention": {
              "total": 0.00522208023071289,
              "qkv_proj": 0.0026320319175720214,
              "rope": 0.00021539199352264404,
              "kv_append": 0.00018467199802398683,
              "attention_op": 0.0006639999747276306,
              "o_proj": 0.0014154239892959595
            },
            "ffn": 0.015049632072448731
          },
          "layer_6": {
            "total": 0.020445280075073242,
            "attention": {
              "total": 0.005261280059814453,
              "qkv_proj": 0.0026315200328826905,
              "rope": 0.0002136320024728775,
              "kv_append": 0.00020521600544452667,
              "attention_op": 0.0006672319769859314,
              "o_proj": 0.001431712031364441
            },
            "ffn": 0.015121600151062013
          },
          "layer_7": {
            "total": 0.020399744033813477,
            "attention": {
              "total": 0.00526364803314209,
              "qkv_proj": 0.002650336027145386,
              "rope": 0.00021452799439430236,
              "kv_append": 0.00018588800728321076,
              "attention_op": 0.000670304000377655,
              "o_proj": 0.0014301439523696899
            },
            "ffn": 0.01507414436340332
          },
          "layer_8": {
            "total": 0.020277919769287108,
            "attention": {
              "total": 0.0052312641143798825,
              "qkv_proj": 0.0026353280544281006,
              "rope": 0.00021270400285720826,
              "kv_append": 0.0001855359971523285,
              "attention_op": 0.0006619520187377929,
              "o_proj": 0.0014213440418243408
            },
            "ffn": 0.01498259162902832
          },
          "layer_9": {
            "total": 0.02032649612426758,
            "attention": {
              "total": 0.005234015941619873,
              "qkv_proj": 0.0026378560066223143,
              "rope": 0.00021372799575328826,
              "kv_append": 0.00018540799617767335,
              "attention_op": 0.0006641600131988525,
              "o_proj": 0.0014188159704208374
            },
            "ffn": 0.01502905559539795
          },
          "layer_10": {
            "total": 0.020296512603759767,
            "attention": {
              "total": 0.005238431930541992,
              "qkv_proj": 0.0026338560581207274,
              "rope": 0.00021372799575328826,
              "kv_append": 0.0001894399970769882,
              "attention_op": 0.0006637439727783203,
              "o_proj": 0.0014224319458007813
            },
            "ffn": 0.014996288299560546
          },
          "layer_11": {
            "total": 0.02029942321777344,
            "attention": {
              "total": 0.00523308801651001,
              "qkv_proj": 0.0026415040493011476,
              "rope": 0.00021225599944591522,
              "kv_append": 0.0001815039962530136,
              "attention_op": 0.0006627839803695679,
              "o_proj": 0.0014211200475692748
            },
            "ffn": 0.015005536079406738
          },
          "layer_12": {
            "total": 0.020297504425048827,
            "attention": {
              "total": 0.005232895851135254,
              "qkv_proj": 0.0026365439891815187,
              "rope": 0.00021296000480651857,
              "kv_append": 0.0001825280040502548,
              "attention_op": 0.0006646400094032287,
              "o_proj": 0.0014208639860153198
            },
            "ffn": 0.015001824378967285
          },
          "layer_13": {
            "total": 0.020300928115844726,
            "attention": {
              "total": 0.005225759983062744,
              "qkv_proj": 0.0026325759887695314,
              "rope": 0.00021219199895858765,
              "kv_append": 0.00018799999356269837,
              "attention_op": 0.0006570559740066528,
              "o_proj": 0.0014237760305404663
            },
            "ffn": 0.015012831687927245
          },
          "layer_14": {
            "total": 0.02035852813720703,
            "attention": {
              "total": 0.005253087997436523,
              "qkv_proj": 0.002645375967025757,
              "rope": 0.00021145600080490112,
              "kv_append": 0.00018665599822998048,
              "attention_op": 0.0006671040058135986,
              "o_proj": 0.0014278719425201416
            },
            "ffn": 0.015042880058288573
          },
          "layer_15": {
            "total": 0.020193855285644532,
            "attention": {
              "total": 0.005211808204650879,
              "qkv_proj": 0.002622368097305298,
              "rope": 0.0002190079987049103,
              "kv_append": 0.0001826239973306656,
              "attention_op": 0.0006575040221214294,
              "o_proj": 0.0014152640104293822
            },
            "ffn": 0.014922016143798828
          },
          "layer_16": {
            "total": 0.020215423583984374,
            "attention": {
              "total": 0.005213664054870605,
              "qkv_proj": 0.0026282880306243896,
              "rope": 0.0002149759978055954,
              "kv_append": 0.00018486399948596956,
              "attention_op": 0.0006561920046806336,
              "o_proj": 0.0014148800373077392
            },
            "ffn": 0.014938400268554688
          },
          "layer_17": {
            "total": 0.02049830436706543,
            "attention": {
              "total": 0.005210080146789551,
              "qkv_proj": 0.0026185920238494874,
              "rope": 0.0002163520008325577,
              "kv_append": 0.00018335999548435211,
              "attention_op": 0.0006580479741096496,
              "o_proj": 0.0014207359552383422
            },
            "ffn": 0.015226304054260254
          },
          "layer_18": {
            "total": 0.02089481544494629,
            "attention": {
              "total": 0.005373983860015869,
              "qkv_proj": 0.0027105600833892823,
              "rope": 0.00021353599429130553,
              "kv_append": 0.0001931519955396652,
              "attention_op": 0.0006823040246963501,
              "o_proj": 0.001458176016807556
            },
            "ffn": 0.015457599639892579
          },
          "layer_19": {
            "total": 0.020756128311157227,
            "attention": {
              "total": 0.00535920000076294,
              "qkv_proj": 0.0027050240039825438,
              "rope": 0.00021507200598716735,
              "kv_append": 0.0001826239973306656,
              "attention_op": 0.0006844800114631653,
              "o_proj": 0.001458624005317688
            },
            "ffn": 0.01533513641357422
          },
          "layer_20": {
            "total": 0.0206625919342041,
            "attention": {
              "total": 0.005311200141906738,
              "qkv_proj": 0.00267795205116272,
              "rope": 0.0002133760005235672,
              "kv_append": 0.00018627199530601502,
              "attention_op": 0.0006725440025329589,
              "o_proj": 0.0014388480186462403
            },
            "ffn": 0.015278559684753418
          },
          "layer_21": {
            "total": 0.020568992614746092,
            "attention": {
              "total": 0.005271359920501709,
              "qkv_proj": 0.002655103921890259,
              "rope": 0.00021596799790859223,
              "kv_append": 0.00018278400599956512,
              "attention_op": 0.0006690880060195922,
              "o_proj": 0.0014339519739151002
            },
            "ffn": 0.015164064407348634
          },
          "layer_22": {
            "total": 0.020713727951049806,
            "attention": {
              "total": 0.00552566385269165,
              "qkv_proj": 0.0026661760807037355,
              "rope": 0.00023817600309848785,
              "kv_append": 0.00035839998722076414,
              "attention_op": 0.0007024000287055969,
              "o_proj": 0.0014368959665298463
            },
            "ffn": 0.0151244478225708
          },
          "layer_23": {
            "total": 0.020321279525756835,
            "attention": {
              "total": 0.00525871992111206,
              "qkv_proj": 0.0026514239311218263,
              "rope": 0.00021491199731826782,
              "kv_append": 0.00018454399704933167,
              "attention_op": 0.0006681920289993286,
              "o_proj": 0.0014265279769897462
            },
            "ffn": 0.015001503944396973
          },
          "layer_24": {
            "total": 0.02040969657897949,
            "attention": {
              "total": 0.005228640079498291,
              "qkv_proj": 0.0026373438835144043,
              "rope": 0.00021199999749660492,
              "kv_append": 0.00018396799266338348,
              "attention_op": 0.0006633599996566773,
              "o_proj": 0.0014202239513397216
            },
            "ffn": 0.01511836814880371
          },
          "layer_25": {
            "total": 0.02043414306640625,
            "attention": {
              "total": 0.0052687678337097164,
              "qkv_proj": 0.0026513919830322267,
              "rope": 0.00021481600403785707,
              "kv_append": 0.00019232000410556794,
              "attention_op": 0.0006709439754486084,
              "o_proj": 0.0014254720211029053
            },
            "ffn": 0.015102335929870606
          },
          "layer_26": {
            "total": 0.020449151992797853,
            "attention": {
              "total": 0.005272768020629883,
              "qkv_proj": 0.0026506240367889402,
              "rope": 0.00021340799331665038,
              "kv_append": 0.00019126400351524353,
              "attention_op": 0.0006695680022239685,
              "o_proj": 0.0014329919815063478
            },
            "ffn": 0.015115551948547364
          },
          "layer_27": {
            "total": 0.020692127227783203,
            "attention": {
              "total": 0.005265312194824219,
              "qkv_proj": 0.0026512959003448487,
              "rope": 0.0002143999934196472,
              "kv_append": 0.00018281599879264832,
              "attention_op": 0.0006703680157661438,
              "o_proj": 0.0014318079948425293
            },
            "ffn": 0.01536633586883545
          },
          "layer_28": {
            "total": 0.02089638328552246,
            "attention": {
              "total": 0.00533187198638916,
              "qkv_proj": 0.002693183898925781,
              "rope": 0.00021385599672794342,
              "kv_append": 0.0001820800006389618,
              "attention_op": 0.0006766719818115235,
              "o_proj": 0.0014552639722824096
            },
            "ffn": 0.015501312255859375
          },
          "layer_29": {
            "total": 0.020956192016601562,
            "attention": {
              "total": 0.005391456127166748,
              "qkv_proj": 0.0027151360511779785,
              "rope": 0.00021465599536895752,
              "kv_append": 0.0001937599927186966,
              "attention_op": 0.0006877440214157105,
              "o_proj": 0.0014644479751586914
            },
            "ffn": 0.015501407623291016
          },
          "layer_30": {
            "total": 0.020785503387451172,
            "attention": {
              "total": 0.005379263877868652,
              "qkv_proj": 0.0027058560848236086,
              "rope": 0.0002143999934196472,
              "kv_append": 0.0001937599927186966,
              "attention_op": 0.0006854720115661621,
              "o_proj": 0.001464959979057312
            },
            "ffn": 0.015343584060668946
          },
          "layer_31": {
            "total": 0.020455711364746092,
            "attention": {
              "total": 0.005278016090393066,
              "qkv_proj": 0.0026538879871368408,
              "rope": 0.00021622399985790253,
              "kv_append": 0.0001966080069541931,
              "attention_op": 0.0006668480038642883,
              "o_proj": 0.0014291199445724486
            },
            "ffn": 0.015117440223693848
          }
        }
      },
      "lm_head": 0.04501103973388672
    },
    "last_decode_op_times": {
      "input_preparation": 0.00021040000021457672,
      "kv_cache_allocation": 0.0005051839947700501,
      "flashinfer_planning": 0.00013120000064373018,
      "embedding_lookup": 3.167999908328056e-05,
      "transformer_layers": {
        "layer_time": 0.026904703974723818,
        "attention_time": 0.017829439938068386,
        "ffn_time": 0.007675776034593582,
        "detailed_layers": {
          "layer_0": {
            "total": 0.0008903040289878845,
            "attention": {
              "total": 0.0006068480014801025,
              "qkv_proj": 0.0001462399959564209,
              "rope": 2.7135999873280526e-05,
              "kv_append": 9.990400075912476e-05,
              "attention_op": 0.00017955200374126436,
              "o_proj": 5.724800005555153e-05
            },
            "ffn": 0.00024140800535678864
          },
          "layer_1": {
            "total": 0.000852512001991272,
            "attention": {
              "total": 0.0005679680109024048,
              "qkv_proj": 0.0001210239976644516,
              "rope": 2.5216000154614447e-05,
              "kv_append": 8.700799942016601e-05,
              "attention_op": 0.00017868800461292268,
              "o_proj": 5.503999814391136e-05
            },
            "ffn": 0.00024038399755954744
          },
          "layer_2": {
            "total": 0.0008431680202484131,
            "attention": {
              "total": 0.0005598080158233643,
              "qkv_proj": 0.00012038400024175644,
              "rope": 2.5439999997615813e-05,
              "kv_append": 8.345600217580795e-05,
              "attention_op": 0.00017769600450992585,
              "o_proj": 5.436800047755242e-05
            },
            "ffn": 0.00024003200232982635
          },
          "layer_3": {
            "total": 0.0008384000062942505,
            "attention": {
              "total": 0.00055731201171875,
              "qkv_proj": 0.00011910399794578553,
              "rope": 2.5216000154614447e-05,
              "kv_append": 8.265600353479385e-05,
              "attention_op": 0.00017599999904632568,
              "o_proj": 5.3440000861883166e-05
            },
            "ffn": 0.0002377600073814392
          },
          "layer_4": {
            "total": 0.0008486719727516174,
            "attention": {
              "total": 0.0005542399883270263,
              "qkv_proj": 0.00011785600334405899,
              "rope": 2.4800000712275504e-05,
              "kv_append": 8.191999793052673e-05,
              "attention_op": 0.00017628799378871916,
              "o_proj": 5.44000007212162e-05
            },
            "ffn": 0.00025040000677108767
          },
          "layer_5": {
            "total": 0.0008426560163497925,
            "attention": {
              "total": 0.000559552013874054,
              "qkv_proj": 0.00011999999731779099,
              "rope": 2.486399933695793e-05,
              "kv_append": 8.336000144481659e-05,
              "attention_op": 0.00017750400304794312,
              "o_proj": 5.35999983549118e-05
            },
            "ffn": 0.00023843200504779815
          },
          "layer_6": {
            "total": 0.0008366720080375671,
            "attention": {
              "total": 0.0005551679730415345,
              "qkv_proj": 0.0001175680011510849,
              "rope": 2.4927999824285508e-05,
              "kv_append": 8.275199681520462e-05,
              "attention_op": 0.00017740799486637115,
              "o_proj": 5.270399898290634e-05
            },
            "ffn": 0.00023827199637889863
          },
          "layer_7": {
            "total": 0.0008402559757232667,
            "attention": {
              "total": 0.0005549759864807128,
              "qkv_proj": 0.00011961600184440613,
              "rope": 2.486399933695793e-05,
              "kv_append": 8.09279978275299e-05,
              "attention_op": 0.00017603200674057008,
              "o_proj": 5.481600016355515e-05
            },
            "ffn": 0.00024134400486946106
          },
          "layer_8": {
            "total": 0.0008375359773635865,
            "attention": {
              "total": 0.000555296003818512,
              "qkv_proj": 0.00011894399672746658,
              "rope": 2.4480000138282777e-05,
              "kv_append": 8.169600367546081e-05,
              "attention_op": 0.00017849600315093995,
              "o_proj": 5.3087998181581494e-05
            },
            "ffn": 0.00023868800699710846
          },
          "layer_9": {
            "total": 0.000840448021888733,
            "attention": {
              "total": 0.0005564799904823303,
              "qkv_proj": 0.00011852800101041793,
              "rope": 2.4095999076962472e-05,
              "kv_append": 8.207999914884568e-05,
              "attention_op": 0.00017708800733089446,
              "o_proj": 5.465599894523621e-05
            },
            "ffn": 0.00024003200232982635
          },
          "layer_10": {
            "total": 0.000836896002292633,
            "attention": {
              "total": 0.0005551999807357788,
              "qkv_proj": 0.00012054400146007538,
              "rope": 2.4831999093294143e-05,
              "kv_append": 8.256000280380249e-05,
              "attention_op": 0.00017478400468826295,
              "o_proj": 5.443200096487999e-05
            },
            "ffn": 0.00023849600553512573
          },
          "layer_11": {
            "total": 0.0008328639864921569,
            "attention": {
              "total": 0.0005501440167427063,
              "qkv_proj": 0.00011615999788045883,
              "rope": 2.5087999179959297e-05,
              "kv_append": 8.086399734020233e-05,
              "attention_op": 0.00017520000040531158,
              "o_proj": 5.379199981689453e-05
            },
            "ffn": 0.0002388480007648468
          },
          "layer_12": {
            "total": 0.0008366720080375671,
            "attention": {
              "total": 0.0005526080131530762,
              "qkv_proj": 0.00011779200285673141,
              "rope": 2.4960000067949296e-05,
              "kv_append": 8.111999928951264e-05,
              "attention_op": 0.000177279993891716,
              "o_proj": 5.366399884223938e-05
            },
            "ffn": 0.00023977600038051604
          },
          "layer_13": {
            "total": 0.000838047981262207,
            "attention": {
              "total": 0.0005530239939689636,
              "qkv_proj": 0.00011721599847078323,
              "rope": 2.5216000154614447e-05,
              "kv_append": 8.083199709653854e-05,
              "attention_op": 0.00017577600479125977,
              "o_proj": 5.3727999329566956e-05
            },
            "ffn": 0.00024092799425125123
          },
          "layer_14": {
            "total": 0.0008551999926567078,
            "attention": {
              "total": 0.0005722240209579467,
              "qkv_proj": 0.0001331840008497238,
              "rope": 2.4191999807953834e-05,
              "kv_append": 8.310399949550629e-05,
              "attention_op": 0.00017817600071430207,
              "o_proj": 5.3472001105546954e-05
            },
            "ffn": 0.00023948800563812256
          },
          "layer_15": {
            "total": 0.0008350719809532166,
            "attention": {
              "total": 0.0005533760190010071,
              "qkv_proj": 0.00011763200163841247,
              "rope": 2.5056000798940658e-05,
              "kv_append": 8.019199967384338e-05,
              "attention_op": 0.00017776000499725343,
              "o_proj": 5.3536001592874524e-05
            },
            "ffn": 0.00023785600066184996
          },
          "layer_16": {
            "total": 0.0008350399732589722,
            "attention": {
              "total": 0.000551360011100769,
              "qkv_proj": 0.00011776000261306762,
              "rope": 2.3840000852942468e-05,
              "kv_append": 8.054400235414506e-05,
              "attention_op": 0.00017689600586891176,
              "o_proj": 5.41439987719059e-05
            },
            "ffn": 0.00023926399648189546
          },
          "layer_17": {
            "total": 0.0008317440152168274,
            "attention": {
              "total": 0.0005485119819641114,
              "qkv_proj": 0.00011606399714946746,
              "rope": 2.4159999564290046e-05,
              "kv_append": 7.926400005817413e-05,
              "attention_op": 0.00017590400576591493,
              "o_proj": 5.340800061821938e-05
            },
            "ffn": 0.00023942400515079498
          },
          "layer_18": {
            "total": 0.0008444479703903199,
            "attention": {
              "total": 0.0005521280169487,
              "qkv_proj": 0.0001162559986114502,
              "rope": 2.473600022494793e-05,
              "kv_append": 8.079999685287475e-05,
              "attention_op": 0.00017737600207328797,
              "o_proj": 5.3759999573230744e-05
            },
            "ffn": 0.00024831999838352206
          },
          "layer_19": {
            "total": 0.0008329920172691345,
            "attention": {
              "total": 0.0005519359707832337,
              "qkv_proj": 0.0001181119978427887,
              "rope": 2.4831999093294143e-05,
              "kv_append": 8.048000186681748e-05,
              "attention_op": 0.00017689600586891176,
              "o_proj": 5.318399891257286e-05
            },
            "ffn": 0.0002372799962759018
          },
          "layer_20": {
            "total": 0.0008395839929580688,
            "attention": {
              "total": 0.0005571839809417724,
              "qkv_proj": 0.000118367999792099,
              "rope": 2.4800000712275504e-05,
              "kv_append": 8.303999900817871e-05,
              "attention_op": 0.00017644800245761872,
              "o_proj": 5.452800169587135e-05
            },
            "ffn": 0.00023868800699710846
          },
          "layer_21": {
            "total": 0.0008357120156288147,
            "attention": {
              "total": 0.0005512639880180358,
              "qkv_proj": 0.00011708799749612808,
              "rope": 2.42880005389452e-05,
              "kv_append": 8.019199967384338e-05,
              "attention_op": 0.0001759680062532425,
              "o_proj": 5.4016001522541044e-05
            },
            "ffn": 0.00024057599902153014
          },
          "layer_22": {
            "total": 0.0008377599716186524,
            "attention": {
              "total": 0.000555903971195221,
              "qkv_proj": 0.00011881600320339203,
              "rope": 2.42880005389452e-05,
              "kv_append": 8.153600245714187e-05,
              "attention_op": 0.00017849600315093995,
              "o_proj": 5.263999849557876e-05
            },
            "ffn": 0.00023824000358581542
          },
          "layer_23": {
            "total": 0.0008420479893684387,
            "attention": {
              "total": 0.0005594239830970764,
              "qkv_proj": 0.0001173119992017746,
              "rope": 2.425600029528141e-05,
              "kv_append": 8.108799904584885e-05,
              "attention_op": 0.00018278400599956512,
              "o_proj": 5.443200096487999e-05
            },
            "ffn": 0.00023766399919986726
          },
          "layer_24": {
            "total": 0.0008404160141944885,
            "attention": {
              "total": 0.0005553920269012452,
              "qkv_proj": 0.00011760000139474868,
              "rope": 2.454400062561035e-05,
              "kv_append": 8.390399813652039e-05,
              "attention_op": 0.00017555199563503264,
              "o_proj": 5.4944001138210295e-05
            },
            "ffn": 0.00024092799425125123
          },
          "layer_25": {
            "total": 0.0008398720026016235,
            "attention": {
              "total": 0.00055622398853302,
              "qkv_proj": 0.0001178240031003952,
              "rope": 2.457600086927414e-05,
              "kv_append": 8.057600259780883e-05,
              "attention_op": 0.00017724800109863282,
              "o_proj": 5.382400006055832e-05
            },
            "ffn": 0.0002396800071001053
          },
          "layer_26": {
            "total": 0.0008353279829025268,
            "attention": {
              "total": 0.0005516160130500794,
              "qkv_proj": 0.00011833599954843522,
              "rope": 2.5183999910950662e-05,
              "kv_append": 8.179199695587158e-05,
              "attention_op": 0.00017529599368572236,
              "o_proj": 5.2992001175880435e-05
            },
            "ffn": 0.0002407359927892685
          },
          "layer_27": {
            "total": 0.0008313599824905396,
            "attention": {
              "total": 0.0005487359762191773,
              "qkv_proj": 0.00011670400202274322,
              "rope": 2.4927999824285508e-05,
              "kv_append": 7.887999713420867e-05,
              "attention_op": 0.00017632000148296357,
              "o_proj": 5.2960000932216646e-05
            },
            "ffn": 0.00023871999979019164
          },
          "layer_28": {
            "total": 0.0008555520176887513,
            "attention": {
              "total": 0.0005718079805374145,
              "qkv_proj": 0.00013622400164604187,
              "rope": 2.4768000468611716e-05,
              "kv_append": 8.316799998283387e-05,
              "attention_op": 0.00017504000663757325,
              "o_proj": 5.404800176620483e-05
            },
            "ffn": 0.00024038399755954744
          },
          "layer_29": {
            "total": 0.0008303040266036988,
            "attention": {
              "total": 0.0005502399802207947,
              "qkv_proj": 0.00011689600348472595,
              "rope": 2.486399933695793e-05,
              "kv_append": 8.012799918651581e-05,
              "attention_op": 0.000176256000995636,
              "o_proj": 5.25440014898777e-05
            },
            "ffn": 0.00023686400055885316
          },
          "layer_30": {
            "total": 0.0008328959941864013,
            "attention": {
              "total": 0.0005505920052528381,
              "qkv_proj": 0.00011766400188207626,
              "rope": 2.473600022494793e-05,
              "kv_append": 8.06720033288002e-05,
              "attention_op": 0.00017584000527858735,
              "o_proj": 5.2799999713897704e-05
            },
            "ffn": 0.00023900799453258515
          },
          "layer_31": {
            "total": 0.0008342720270156861,
            "attention": {
              "total": 0.0005528960227966309,
              "qkv_proj": 0.00011779200285673141,
              "rope": 2.4480000138282777e-05,
              "kv_append": 8.102399855852127e-05,
              "attention_op": 0.0001769600063562393,
              "o_proj": 5.257600173354149e-05
            },
            "ffn": 0.00023785600066184996
          }
        }
      },
      "lm_head": 0.0004896000027656555
    },
    "longest_op": "kv_cache_allocation",
    "longest_op_time": 0.0005051839947700501
  },
  {
    "decode_length": 1024,
    "log_decode_length": 10.0,
    "prefill_time": 0.7472355365753174,
    "decode_time": 30.453807830810547,
    "total_time": 31.201043367385864,
    "prefill_op_times": {
      "input_preparation": 0.00023375999927520753,
      "kv_cache_allocation": 0.0006885120272636414,
      "flashinfer_planning": 0.00027964800596237183,
      "embedding_lookup": 0.0004294080138206482,
      "transformer_layers": {
        "layer_time": 0.654776294708252,
        "attention_time": 0.16856716680526734,
        "ffn_time": 0.48421216011047363,
        "detailed_layers": {
          "layer_0": {
            "total": 0.019363231658935547,
            "attention": {
              "total": 0.005077087879180908,
              "qkv_proj": 0.002532383918762207,
              "rope": 0.00021376000344753266,
              "kv_append": 0.00022124800086021422,
              "attention_op": 0.0006164479851722718,
              "o_proj": 0.0013802239894866943
            },
            "ffn": 0.014227295875549316
          },
          "layer_1": {
            "total": 0.019382112503051756,
            "attention": {
              "total": 0.005056672096252442,
              "qkv_proj": 0.002564192056655884,
              "rope": 0.0002141759991645813,
              "kv_append": 0.00019414399564266204,
              "attention_op": 0.0005860800147056579,
              "o_proj": 0.001383903980255127
            },
            "ffn": 0.014261887550354005
          },
          "layer_2": {
            "total": 0.019683135986328124,
            "attention": {
              "total": 0.005059487819671631,
              "qkv_proj": 0.0025682239532470704,
              "rope": 0.00021158400177955628,
              "kv_append": 0.000191103994846344,
              "attention_op": 0.0005891199707984924,
              "o_proj": 0.0013843200206756592
            },
            "ffn": 0.014560000419616699
          },
          "layer_3": {
            "total": 0.020285184860229493,
            "attention": {
              "total": 0.005238048076629639,
              "qkv_proj": 0.0026350719928741454,
              "rope": 0.0002122880071401596,
              "kv_append": 0.0001841599941253662,
              "attention_op": 0.0006683200001716614,
              "o_proj": 0.0014251519441604613
            },
            "ffn": 0.014986528396606445
          },
          "layer_4": {
            "total": 0.020282720565795897,
            "attention": {
              "total": 0.005231008052825927,
              "qkv_proj": 0.0026294400691986085,
              "rope": 0.00021452799439430236,
              "kv_append": 0.00018556800484657287,
              "attention_op": 0.0006642240285873413,
              "o_proj": 0.0014234880208969117
            },
            "ffn": 0.014987360000610352
          },
          "layer_5": {
            "total": 0.020508159637451173,
            "attention": {
              "total": 0.005249663829803467,
              "qkv_proj": 0.0026443519592285157,
              "rope": 0.00021388800442218782,
              "kv_append": 0.00018409599363803863,
              "attention_op": 0.0006670399904251099,
              "o_proj": 0.0014287359714508056
            },
            "ffn": 0.015193920135498046
          },
          "layer_6": {
            "total": 0.020802879333496095,
            "attention": {
              "total": 0.005337120056152344,
              "qkv_proj": 0.0026899840831756594,
              "rope": 0.000213919997215271,
              "kv_append": 0.00018854400515556336,
              "attention_op": 0.0006782400012016296,
              "o_proj": 0.0014532159566879273
            },
            "ffn": 0.01540351963043213
          },
          "layer_7": {
            "total": 0.020779903411865235,
            "attention": {
              "total": 0.005334976196289062,
              "qkv_proj": 0.0026891520023345945,
              "rope": 0.00021244800090789795,
              "kv_append": 0.0001836480051279068,
              "attention_op": 0.0006779199838638306,
              "o_proj": 0.0014567359685897826
            },
            "ffn": 0.015383808135986329
          },
          "layer_8": {
            "total": 0.020635072708129882,
            "attention": {
              "total": 0.005329376220703125,
              "qkv_proj": 0.0026863679885864257,
              "rope": 0.000213919997215271,
              "kv_append": 0.00018457600474357605,
              "attention_op": 0.0006747199892997742,
              "o_proj": 0.001453760027885437
            },
            "ffn": 0.015240768432617187
          },
          "layer_9": {
            "total": 0.020406208038330077,
            "attention": {
              "total": 0.005267007827758789,
              "qkv_proj": 0.0026494400501251222,
              "rope": 0.00021542400121688844,
              "kv_append": 0.00019446399807929992,
              "attention_op": 0.0006678720116615295,
              "o_proj": 0.0014301120042800903
            },
            "ffn": 0.015075712203979493
          },
          "layer_10": {
            "total": 0.020416383743286134,
            "attention": {
              "total": 0.005242432117462158,
              "qkv_proj": 0.0026357119083404543,
              "rope": 0.00021427200734615325,
              "kv_append": 0.0001897920072078705,
              "attention_op": 0.0006637439727783203,
              "o_proj": 0.0014248319864273071
            },
            "ffn": 0.015110655784606934
          },
          "layer_11": {
            "total": 0.020426111221313478,
            "attention": {
              "total": 0.005256319999694824,
              "qkv_proj": 0.0026529600620269775,
              "rope": 0.00021193599700927734,
              "kv_append": 0.0001826239973306656,
              "attention_op": 0.0006665920019149781,
              "o_proj": 0.001429087996482849
            },
            "ffn": 0.015109248161315918
          },
          "layer_12": {
            "total": 0.020377376556396484,
            "attention": {
              "total": 0.0052713918685913085,
              "qkv_proj": 0.002652928113937378,
              "rope": 0.00021296000480651857,
              "kv_append": 0.0001943040043115616,
              "attention_op": 0.0006673920154571533,
              "o_proj": 0.0014308160543441773
            },
            "ffn": 0.01504319953918457
          },
          "layer_13": {
            "total": 0.020470144271850586,
            "attention": {
              "total": 0.005249216079711914,
              "qkv_proj": 0.002636768102645874,
              "rope": 0.00021692800521850585,
              "kv_append": 0.00018684799969196318,
              "attention_op": 0.0006661760210990906,
              "o_proj": 0.001428320050239563
            },
            "ffn": 0.015157471656799317
          },
          "layer_14": {
            "total": 0.020570720672607422,
            "attention": {
              "total": 0.0052845759391784665,
              "qkv_proj": 0.0026628479957580566,
              "rope": 0.00021059200167655945,
              "kv_append": 0.000188960000872612,
              "attention_op": 0.0006716480255126953,
              "o_proj": 0.0014380480051040649
            },
            "ffn": 0.01522374439239502
          },
          "layer_15": {
            "total": 0.020594207763671876,
            "attention": {
              "total": 0.005296832084655762,
              "qkv_proj": 0.0026656320095062255,
              "rope": 0.00021404799818992615,
              "kv_append": 0.0001814720034599304,
              "attention_op": 0.0006739519834518433,
              "o_proj": 0.0014500479698181152
            },
            "ffn": 0.015236639976501464
          },
          "layer_16": {
            "total": 0.020565792083740233,
            "attention": {
              "total": 0.00529318380355835,
              "qkv_proj": 0.002664031982421875,
              "rope": 0.00021318399906158447,
              "kv_append": 0.00018371200561523437,
              "attention_op": 0.0006750720143318176,
              "o_proj": 0.0014410560131072998
            },
            "ffn": 0.015206879615783691
          },
          "layer_17": {
            "total": 0.020569568634033204,
            "attention": {
              "total": 0.0052986559867858884,
              "qkv_proj": 0.0026684160232543943,
              "rope": 0.00021804800629615783,
              "kv_append": 0.00018905599415302277,
              "attention_op": 0.000672767996788025,
              "o_proj": 0.0014361920356750488
            },
            "ffn": 0.015209440231323243
          },
          "layer_18": {
            "total": 0.020457408905029298,
            "attention": {
              "total": 0.005279967784881592,
              "qkv_proj": 0.0026623680591583254,
              "rope": 0.00021241599321365355,
              "kv_append": 0.00018748800456523895,
              "attention_op": 0.000671999990940094,
              "o_proj": 0.001432703971862793
            },
            "ffn": 0.015116512298583984
          },
          "layer_19": {
            "total": 0.020525279998779296,
            "attention": {
              "total": 0.005262976169586182,
              "qkv_proj": 0.002650815963745117,
              "rope": 0.00021411199867725372,
              "kv_append": 0.00018540799617767335,
              "attention_op": 0.0006675840020179748,
              "o_proj": 0.0014292160272598266
            },
            "ffn": 0.015201472282409667
          },
          "layer_20": {
            "total": 0.020832256317138673,
            "attention": {
              "total": 0.005279007911682129,
              "qkv_proj": 0.0026645119190216063,
              "rope": 0.00021267199516296386,
              "kv_append": 0.00018265600502490997,
              "attention_op": 0.0006733760237693787,
              "o_proj": 0.0014351040124893188
            },
            "ffn": 0.015487135887145996
          },
          "layer_21": {
            "total": 0.020935327529907226,
            "attention": {
              "total": 0.005372960090637207,
              "qkv_proj": 0.0027147839069366457,
              "rope": 0.00021692800521850585,
              "kv_append": 0.00018374399840831757,
              "attention_op": 0.0006840959787368775,
              "o_proj": 0.0014599679708480835
            },
            "ffn": 0.015499456405639649
          },
          "layer_22": {
            "total": 0.020964832305908204,
            "attention": {
              "total": 0.005387648105621338,
              "qkv_proj": 0.0027035200595855713,
              "rope": 0.00021328000724315642,
              "kv_append": 0.00018889600038528442,
              "attention_op": 0.0006945599913597107,
              "o_proj": 0.0014638400077819824
            },
            "ffn": 0.015515359878540039
          },
          "layer_23": {
            "total": 0.020595008850097657,
            "attention": {
              "total": 0.005326911926269531,
              "qkv_proj": 0.002707711935043335,
              "rope": 0.00021385599672794342,
              "kv_append": 0.0001822720021009445,
              "attention_op": 0.0006758400201797485,
              "o_proj": 0.0014336639642715454
            },
            "ffn": 0.015206175804138184
          },
          "layer_24": {
            "total": 0.02055721664428711,
            "attention": {
              "total": 0.00528879976272583,
              "qkv_proj": 0.0026694400310516356,
              "rope": 0.00021376000344753266,
              "kv_append": 0.00018246400356292724,
              "attention_op": 0.0006735680103302002,
              "o_proj": 0.001439136028289795
            },
            "ffn": 0.015204511642456054
          },
          "layer_25": {
            "total": 0.020417760848999024,
            "attention": {
              "total": 0.005263936042785644,
              "qkv_proj": 0.0026539199352264404,
              "rope": 0.00021468800306320192,
              "kv_append": 0.0001860799938440323,
              "attention_op": 0.0006688320040702819,
              "o_proj": 0.0014252480268478393
            },
            "ffn": 0.015090815544128418
          },
          "layer_26": {
            "total": 0.02044495964050293,
            "attention": {
              "total": 0.005268159866333008,
              "qkv_proj": 0.0026499199867248534,
              "rope": 0.000212896004319191,
              "kv_append": 0.00018883199989795684,
              "attention_op": 0.0006722880005836486,
              "o_proj": 0.001429919958114624
            },
            "ffn": 0.015115039825439453
          },
          "layer_27": {
            "total": 0.020406400680541992,
            "attention": {
              "total": 0.0052540478706359865,
              "qkv_proj": 0.00264851188659668,
              "rope": 0.0002143999934196472,
              "kv_append": 0.00018175999820232392,
              "attention_op": 0.0006658239960670472,
              "o_proj": 0.0014301120042800903
            },
            "ffn": 0.015091936111450195
          },
          "layer_28": {
            "total": 0.020608831405639648,
            "attention": {
              "total": 0.005285183906555176,
              "qkv_proj": 0.00266214394569397,
              "rope": 0.00021247999370098113,
              "kv_append": 0.00018361599743366242,
              "attention_op": 0.000671455979347229,
              "o_proj": 0.0014431359767913818
            },
            "ffn": 0.015259936332702636
          },
          "layer_29": {
            "total": 0.020643264770507812,
            "attention": {
              "total": 0.005315487861633301,
              "qkv_proj": 0.0026716480255126952,
              "rope": 0.00021305599808692932,
              "kv_append": 0.00019295999407768248,
              "attention_op": 0.0006763839721679688,
              "o_proj": 0.0014476159811019898
            },
            "ffn": 0.015265695571899414
          },
          "layer_30": {
            "total": 0.020665664672851563,
            "attention": {
              "total": 0.005309375762939453,
              "qkv_proj": 0.0026733119487762453,
              "rope": 0.00021235199272632598,
              "kv_append": 0.00018876799941062926,
              "attention_op": 0.0006744959950447083,
              "o_proj": 0.0014459199905395507
            },
            "ffn": 0.015296256065368653
          },
          "layer_31": {
            "total": 0.02060316848754883,
            "attention": {
              "total": 0.005299647808074951,
              "qkv_proj": 0.0026727681159973145,
              "rope": 0.00021481600403785707,
              "kv_append": 0.00018294399976730348,
              "attention_op": 0.0006747519969940185,
              "o_proj": 0.001440000057220459
            },
            "ffn": 0.015243776321411133
          }
        }
      },
      "lm_head": 0.04509193420410156
    },
    "last_decode_op_times": {
      "input_preparation": 0.0002083200067281723,
      "kv_cache_allocation": 0.0006969599723815918,
      "flashinfer_planning": 0.00013152000308036803,
      "embedding_lookup": 3.267199918627739e-05,
      "transformer_layers": {
        "layer_time": 0.029722464025020604,
        "attention_time": 0.020625599980354313,
        "ffn_time": 0.007695968002080918,
        "detailed_layers": {
          "layer_0": {
            "total": 0.000977728009223938,
            "attention": {
              "total": 0.0006919360160827637,
              "qkv_proj": 0.00014640000462532043,
              "rope": 2.6720000430941583e-05,
              "kv_append": 9.92320030927658e-05,
              "attention_op": 0.0002619839906692505,
              "o_proj": 5.536000058054924e-05
            },
            "ffn": 0.00024400000274181366
          },
          "layer_1": {
            "total": 0.0009456319808959961,
            "attention": {
              "total": 0.0006591359972953797,
              "qkv_proj": 0.0001268479973077774,
              "rope": 2.5696000084280967e-05,
              "kv_append": 8.931200206279755e-05,
              "attention_op": 0.00026051199436187745,
              "o_proj": 5.6352000683546066e-05
            },
            "ffn": 0.00024147200584411621
          },
          "layer_2": {
            "total": 0.0009318079948425293,
            "attention": {
              "total": 0.0006459519863128662,
              "qkv_proj": 0.00011878400295972824,
              "rope": 2.4320000782608984e-05,
              "kv_append": 8.406399935483933e-05,
              "attention_op": 0.00026128000020980837,
              "o_proj": 5.452800169587135e-05
            },
            "ffn": 0.00023980799317359925
          },
          "layer_3": {
            "total": 0.0009321280121803284,
            "attention": {
              "total": 0.0006454079747200012,
              "qkv_proj": 0.00012009599804878235,
              "rope": 2.5439999997615813e-05,
              "kv_append": 8.57279971241951e-05,
              "attention_op": 0.0002592320144176483,
              "o_proj": 5.44000007212162e-05
            },
            "ffn": 0.00024220800399780274
          },
          "layer_4": {
            "total": 0.0009258239865303039,
            "attention": {
              "total": 0.0006418240070343018,
              "qkv_proj": 0.00011798399686813354,
              "rope": 2.4703999981284142e-05,
              "kv_append": 8.316799998283387e-05,
              "attention_op": 0.00026003199815750124,
              "o_proj": 5.433600023388863e-05
            },
            "ffn": 0.00023929600417613983
          },
          "layer_5": {
            "total": 0.0009418240189552307,
            "attention": {
              "total": 0.000657535970211029,
              "qkv_proj": 0.00013548800349235535,
              "rope": 2.54720002412796e-05,
              "kv_append": 8.320000022649766e-05,
              "attention_op": 0.0002606399953365326,
              "o_proj": 5.267199873924255e-05
            },
            "ffn": 0.0002412479966878891
          },
          "layer_6": {
            "total": 0.0009267200231552124,
            "attention": {
              "total": 0.0006420800089836121,
              "qkv_proj": 0.00012038400024175644,
              "rope": 2.4607999250292777e-05,
              "kv_append": 8.207999914884568e-05,
              "attention_op": 0.00026044800877571104,
              "o_proj": 5.510399863123894e-05
            },
            "ffn": 0.00024083200097084045
          },
          "layer_7": {
            "total": 0.000918720006942749,
            "attention": {
              "total": 0.0006355199813842773,
              "qkv_proj": 0.00011859200149774551,
              "rope": 2.457600086927414e-05,
              "kv_append": 8.137600123882294e-05,
              "attention_op": 0.0002594560086727142,
              "o_proj": 5.292800068855286e-05
            },
            "ffn": 0.00024035200476646423
          },
          "layer_8": {
            "total": 0.0009216319918632507,
            "attention": {
              "total": 0.0006396800279617309,
              "qkv_proj": 0.00011900799721479416,
              "rope": 2.4831999093294143e-05,
              "kv_append": 8.262400329113006e-05,
              "attention_op": 0.00025977599620819093,
              "o_proj": 5.417599901556969e-05
            },
            "ffn": 0.0002386559993028641
          },
          "layer_9": {
            "total": 0.0009412800073623658,
            "attention": {
              "total": 0.0006571840047836304,
              "qkv_proj": 0.00011852800101041793,
              "rope": 2.5087999179959297e-05,
              "kv_append": 9.219200164079666e-05,
              "attention_op": 0.0002672640085220337,
              "o_proj": 5.382400006055832e-05
            },
            "ffn": 0.0002413119971752167
          },
          "layer_10": {
            "total": 0.0009233279824256897,
            "attention": {
              "total": 0.0006390399932861328,
              "qkv_proj": 0.00011763200163841247,
              "rope": 2.5280000641942024e-05,
              "kv_append": 8.271999657154083e-05,
              "attention_op": 0.00025942400097846987,
              "o_proj": 5.4239999502897264e-05
            },
            "ffn": 0.00024003200232982635
          },
          "layer_11": {
            "total": 0.0009210240244865417,
            "attention": {
              "total": 0.0006371520161628724,
              "qkv_proj": 0.00012028799951076507,
              "rope": 2.4800000712275504e-05,
              "kv_append": 8.233600109815597e-05,
              "attention_op": 0.0002579840123653412,
              "o_proj": 5.3279999643564224e-05
            },
            "ffn": 0.00023996800184249877
          },
          "layer_12": {
            "total": 0.0009241920113563538,
            "attention": {
              "total": 0.000642624020576477,
              "qkv_proj": 0.0001189119964838028,
              "rope": 2.4607999250292777e-05,
              "kv_append": 8.259200304746628e-05,
              "attention_op": 0.0002620159983634949,
              "o_proj": 5.4239999502897264e-05
            },
            "ffn": 0.00023839999735355378
          },
          "layer_13": {
            "total": 0.0009281280040740967,
            "attention": {
              "total": 0.0006405119895935058,
              "qkv_proj": 0.00011903999745845795,
              "rope": 2.473600022494793e-05,
              "kv_append": 8.099199831485748e-05,
              "attention_op": 0.0002592639923095703,
              "o_proj": 5.7792000472545626e-05
            },
            "ffn": 0.00024348799884319305
          },
          "layer_14": {
            "total": 0.0009188159704208375,
            "attention": {
              "total": 0.0006346560120582581,
              "qkv_proj": 0.00011859200149774551,
              "rope": 2.42880005389452e-05,
              "kv_append": 7.952000200748444e-05,
              "attention_op": 0.0002594560086727142,
              "o_proj": 5.3920000791549686e-05
            },
            "ffn": 0.0002404800057411194
          },
          "layer_15": {
            "total": 0.0009239360094070435,
            "attention": {
              "total": 0.0006403520107269287,
              "qkv_proj": 0.00011849600076675414,
              "rope": 2.5119999423623085e-05,
              "kv_append": 8.294399827718735e-05,
              "attention_op": 0.0002603200078010559,
              "o_proj": 5.3984001278877256e-05
            },
            "ffn": 0.00024003200232982635
          },
          "layer_16": {
            "total": 0.0009215679764747619,
            "attention": {
              "total": 0.0006373119950294495,
              "qkv_proj": 0.00011852800101041793,
              "rope": 2.42880005389452e-05,
              "kv_append": 8.291199803352356e-05,
              "attention_op": 0.00025859200954437254,
              "o_proj": 5.356800183653831e-05
            },
            "ffn": 0.0002399359941482544
          },
          "layer_17": {
            "total": 0.0009424639940261841,
            "attention": {
              "total": 0.0006442559957504273,
              "qkv_proj": 0.00012425599992275238,
              "rope": 2.4703999981284142e-05,
              "kv_append": 8.23040008544922e-05,
              "attention_op": 0.0002606399953365326,
              "o_proj": 5.369599908590317e-05
            },
            "ffn": 0.00025494399666786194
          },
          "layer_18": {
            "total": 0.0009222720265388488,
            "attention": {
              "total": 0.0006370239853858948,
              "qkv_proj": 0.00011820799857378006,
              "rope": 2.438399940729141e-05,
              "kv_append": 8.131200075149537e-05,
              "attention_op": 0.00026124799251556397,
              "o_proj": 5.340800061821938e-05
            },
            "ffn": 0.00024143999814987181
          },
          "layer_19": {
            "total": 0.0009184640049934387,
            "attention": {
              "total": 0.000636352002620697,
              "qkv_proj": 0.00011833599954843522,
              "rope": 2.4320000782608984e-05,
              "kv_append": 8.259200304746628e-05,
              "attention_op": 0.0002592320144176483,
              "o_proj": 5.2767999470233916e-05
            },
            "ffn": 0.00023878400027751921
          },
          "layer_20": {
            "total": 0.0009173759818077087,
            "attention": {
              "total": 0.000635263979434967,
              "qkv_proj": 0.00011737599968910218,
              "rope": 2.4768000468611716e-05,
              "kv_append": 8.108799904584885e-05,
              "attention_op": 0.0002587519884109497,
              "o_proj": 5.379199981689453e-05
            },
            "ffn": 0.0002377920001745224
          },
          "layer_21": {
            "total": 0.0009215360283851623,
            "attention": {
              "total": 0.0006381760239601135,
              "qkv_proj": 0.00011875200271606445,
              "rope": 2.4191999807953834e-05,
              "kv_append": 8.303999900817871e-05,
              "attention_op": 0.0002608000040054321,
              "o_proj": 5.3247999399900436e-05
            },
            "ffn": 0.0002407039999961853
          },
          "layer_22": {
            "total": 0.0009279360175132752,
            "attention": {
              "total": 0.0006443520188331605,
              "qkv_proj": 0.00012611199915409088,
              "rope": 2.4607999250292777e-05,
              "kv_append": 8.204799890518189e-05,
              "attention_op": 0.00025939199328422547,
              "o_proj": 5.318399891257286e-05
            },
            "ffn": 0.0002391359955072403
          },
          "layer_23": {
            "total": 0.0009263359904289246,
            "attention": {
              "total": 0.0006420159935951233,
              "qkv_proj": 0.0001194240003824234,
              "rope": 2.4960000067949296e-05,
              "kv_append": 8.409599959850312e-05,
              "attention_op": 0.0002595199942588806,
              "o_proj": 5.3536001592874524e-05
            },
            "ffn": 0.00023987199366092682
          },
          "layer_24": {
            "total": 0.0009164800047874451,
            "attention": {
              "total": 0.0006348479986190796,
              "qkv_proj": 0.00011776000261306762,
              "rope": 2.4320000782608984e-05,
              "kv_append": 8.131200075149537e-05,
              "attention_op": 0.00025942400097846987,
              "o_proj": 5.311999842524528e-05
            },
            "ffn": 0.00023747199773788453
          },
          "layer_25": {
            "total": 0.000921887993812561,
            "attention": {
              "total": 0.0006399040222167969,
              "qkv_proj": 0.00011999999731779099,
              "rope": 2.5312000885605812e-05,
              "kv_append": 8.09279978275299e-05,
              "attention_op": 0.0002596479952335358,
              "o_proj": 5.404800176620483e-05
            },
            "ffn": 0.00023846399784088136
          },
          "layer_26": {
            "total": 0.000981599986553192,
            "attention": {
              "total": 0.000695967972278595,
              "qkv_proj": 0.00011670400202274322,
              "rope": 2.4512000381946565e-05,
              "kv_append": 8.528000116348266e-05,
              "attention_op": 0.00025839999318122864,
              "o_proj": 5.481600016355515e-05
            },
            "ffn": 0.0002417600005865097
          },
          "layer_27": {
            "total": 0.0009188159704208375,
            "attention": {
              "total": 0.0006369280219078064,
              "qkv_proj": 0.00011766400188207626,
              "rope": 2.457600086927414e-05,
              "kv_append": 8.140800148248673e-05,
              "attention_op": 0.00026096001267433166,
              "o_proj": 5.289600044488907e-05
            },
            "ffn": 0.00023900799453258515
          },
          "layer_28": {
            "total": 0.0009168000221252442,
            "attention": {
              "total": 0.0006347519755363464,
              "qkv_proj": 0.0001170239970088005,
              "rope": 2.4480000138282777e-05,
              "kv_append": 8.131200075149537e-05,
              "attention_op": 0.0002592320144176483,
              "o_proj": 5.35999983549118e-05
            },
            "ffn": 0.00023836800456047058
          },
          "layer_29": {
            "total": 0.00091948801279068,
            "attention": {
              "total": 0.0006379839777946472,
              "qkv_proj": 0.00011776000261306762,
              "rope": 2.438399940729141e-05,
              "kv_append": 8.160000294446945e-05,
              "attention_op": 0.0002599039971828461,
              "o_proj": 5.395200103521347e-05
            },
            "ffn": 0.00023817600309848785
          },
          "layer_30": {
            "total": 0.0009219520092010498,
            "attention": {
              "total": 0.0006376320123672486,
              "qkv_proj": 0.00011718399822711945,
              "rope": 2.4191999807953834e-05,
              "kv_append": 8.079999685287475e-05,
              "attention_op": 0.000258976012468338,
              "o_proj": 5.5615998804569246e-05
            },
            "ffn": 0.00023942400515079498
          },
          "layer_31": {
            "total": 0.0009247679710388183,
            "attention": {
              "total": 0.0006422399878501892,
              "qkv_proj": 0.00011907199770212174,
              "rope": 2.5599999353289605e-05,
              "kv_append": 8.316799998283387e-05,
              "attention_op": 0.0002605760097503662,
              "o_proj": 5.3536001592874524e-05
            },
            "ffn": 0.0002391040027141571
          }
        }
      },
      "lm_head": 0.0004875200092792511
    },
    "longest_op": "kv_cache_allocation",
    "longest_op_time": 0.0006969599723815918
  }
]